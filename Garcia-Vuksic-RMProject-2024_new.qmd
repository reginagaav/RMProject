---
title: "Regression Methods Project"
format: pdf
header-includes:
  - \usepackage{xcolor}
---

#### **1. Introduction and Exploratory Data Analysis**

A recent paper (winner of the 2024 IgNobel Prize in Probability) analyzed over 350,000 coin flips to investigate the phenomenon that a coin starting heads-up tends to land heads-up with a probability slightly above 0.5, around 0.51, and similarly for tails-up. While the original paper adopted a Bayesian framework, our goal here is to employ frequentist regression methods to explore this possible bias and the factors that might influence it---such as participant-specific flipping techniques, coin characteristics, and the coin's starting orientation.

-   **State Objectives:**

    -   Clearly define the aims of your analysis.

-   **Outline:**

    -   Provide a roadmap of your report's structure.

**Data Description**

The dataset (in `data-agg.csv`) contains aggregated results from an experiment involving 48 participants flipping 211 different coins. Each row corresponds to the outcomes of flipping a *specific coin* by a *single participant* under two starting orientations: heads-up and tails-up. The columns are:

-   **heads_heads**: Number of flips that started heads-up and ended heads-up.

-   **tails_heads**: Number of flips that started tails-up and ended heads-up.

-   **N_start_heads_up**: Total flips that started heads-up.

-   **N_start_tails_up**: Total flips that started tails-up.

-   **person**: Participant identifier.

-   **coin**: Coin identifier.

We define for each row:

$\begin{aligned} &\text{heads_tails} = N_{\text{start_heads_up}} - \text{heads_heads}, \\ &\text{tails_tails} = N_{\text{start_tails_up}} - \text{tails_heads}, \\ &\text{prob_same_side} = \frac{\text{heads_heads} + \text{tails_tails}}{N_{\text{start_heads_up}} + N_{\text{start_tails_up}}}. \end{aligned}$

​heads_tails=Nstart_heads_up​−heads_heads,tails_tails=Nstart_tails_up​−tails_heads,prob_same_side=Nstart_heads_up​+Nstart_tails_up​heads_heads+tails_tails​.​\$

The overall interest lies in the extent to which $\text{prob_same_side}$ exceeds 0.50, and whether this bias depends on the participant, coin, or starting orientation \*\*maybe also on the learning effects, outcomes of recent flips...?\*\*. Our analysis begins with studying the patterns in the data to inform modeling. 

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Load necessary libraries
library(tidyverse)
library(glue)
library(viridis)

# Read the data
df <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/data-agg.csv") %>%
  mutate(
    person = factor(person),
    coin = factor(coin)
  )

```

**Overall Probability of Landing on the Same Side**

To assess the overall bias, we first compute how often the coin ends on the same side it started.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate flips where the coin landed on the opposite side
df <- df %>%
  mutate(
    heads_tails = N_start_heads_up - heads_heads,
    tails_tails = N_start_tails_up - tails_heads
  )

# Calculate total flips and probabilities
df <- df %>%
  mutate(
    total_flips = N_start_heads_up + N_start_tails_up,
    total_same_side = heads_heads + tails_tails,
    prob_same_side = total_same_side / total_flips,
    prob_heads_to_heads = heads_heads / N_start_heads_up,
    prob_tails_to_tails = tails_tails / N_start_tails_up
  )

# Summary statistics for probability of landing on the same side}
summary_stats <- df %>%
  summarise(
    mean_prob_same_side = mean(prob_same_side, na.rm = TRUE),
    median_prob_same_side = median(prob_same_side, na.rm = TRUE),
    sd_prob_same_side = sd(prob_same_side, na.rm = TRUE)
  )

print(summary_stats)
```

```{r, message=FALSE, warning=FALSE}
#| echo: false
t.test(df$prob_same_side, mu = 0.5, alternative = "two.sided")
```

From these results, we find a **mean probability** of about 0.508, slightly exceeding 0.5. A one-sample t-test against 0.5 indicates a statistically significant difference (p \< 0.05). Although the magnitude of this effect is small, it suggests a bias toward coins landing on the same side they started.

We visualize the distribution of these probabilities in Figure 1.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side
ggplot(df, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[2]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

```

*Figure 1: Histogram of the probability of landing on the same side across all coins and participants.*

Most probabilities cluster around 0.5, but the distribution leans slightly to the right, reflecting the small bias observed. A few outliers exceed 0.6, which we will explore further.

**Participant-Level Analysis**

Next, we examine how this probability varies by participant. Differences in flipping technique or style could drive variation at the individual level.

We sum heads-up and tails-up flips by participant to obtain

$p_i = \frac{(\text{heads_heads})_i + (\text{tails_tails})_i}{(\text{total_flips})_i}​​$

where $(\text{heads_heads})_i$ is the total number of heads outcomes from heads-up starts for participant $i$, etc.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate participant-level probabilities
participant_probs <- df %>%
  group_by(person) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at participant level
participant_summary <- participant_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(participant_summary)

```

The **mean participant-level probability** is around 0.510, slightly higher than the overall mean. This minor increase above the grand mean suggests participants differ in their flipping styles, possibly through differences in technique or consistency. This is illustrated in Figure 2.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side by participant
ggplot(participant_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[3]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side by Participant",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()
```

*Figure 2: Histogram of Probability of Landing on the Same Side by Participant*

Although many participants cluster near 0.5, there are some notable outliers, reinforcing the notion that **participant-specific effects** could be important in modeling. We identify outliers by checking which participants' probabilities lie beyond two standard deviations from the mean.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Identify participants with extreme probabilities
participant_outliers <- participant_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(participant_outliers)

```

**Coin-Level Analysis**

We then group flips by each *coin* to see whether some coins inherently land on the same side more frequently. Analogously, we compute

$q_j = \frac{(\text{heads_heads})_j + (\text{tails_tails})_j}{(\text{total_flips})_j}​​$

where $(\text{heads_heads})_j$ denotes the total number of heads outcomes from heads-up starts for coin \$j\$, etc.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate coin-level probabilities
coin_probs <- df %>%
  group_by(coin) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at coin level
coin_summary <- coin_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(coin_summary)

```

The **mean coin-level probability** is about 0.504, with smaller overall variability compared to participants, as shown in Figure 3.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities by coin
ggplot(coin_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[4]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side by Coin",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()


```

*Figure 3: Histogram of the probability of landing on the same side by coin.*

Coin-level probabilities remain tightly grouped around 0.5. This finding indicates that, **on average**, coin characteristics may not strongly affect the outcome, at least not to the same extent as participant-specific effects. Outliers were identified for coins with probabilities exceeding two standard deviations from the mean.

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify coin outliers
coin_outliers <- coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(coin_outliers)
```

To further investigate, we analyzed person/coin combinations to explore whether specific participant-coin interactions exhibit unusual outcomes.

```{r,message=FALSE,warning=FALSE}
# Calculate probabilities for person/coin combinations
person_coin_probs <- df %>%
  group_by(person, coin) %>%
  summarise(prob_same_side = mean(prob_same_side, na.rm = TRUE), .groups = "drop")

# Identify person/coin combination outliers
person_coin_outliers <- person_coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(person_coin_outliers)
```

TianqiPeng and JanYang were identified as outlier participants.

\*\*maybe say something else??? lol im tired and not so sure\*\*

**Effect of Starting Side**

Finally, we explore whether starting the coin heads-up vs. tails-up alters the likelihood of ending on the same side. We compare:

-   $p_{11}=P(Heads→Heads)$

-   $p_{00}=P(Tails→Tails)$

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Compare probabilities based on starting side
starting_side_probs <- df %>%
  summarise(
    mean_prob_heads_to_heads = mean(prob_heads_to_heads, na.rm = TRUE),
    mean_prob_tails_to_tails = mean(prob_tails_to_tails, na.rm = TRUE),
    sd_prob_heads_to_heads = sd(prob_heads_to_heads, na.rm = TRUE),
    sd_prob_tails_to_tails = sd(prob_tails_to_tails, na.rm = TRUE)
  )

print(starting_side_probs)

```

The results indicate **both** heads-up and tails-up flips have a mean probability of about 0.508 of landing on the same side. A t-test reveals no significant difference between the two groups, implying that "heads-up" vs. "tails-up" starts do not systematically alter the bias once participant and coin factors are averaged out.

ive been thinking of how davison said hypothesis tests are overused is this one of those cases? or is it a reasonable test? i think so but im also overthinking

```{r,message=FALSE, warning=FALSE}
#| echo: false
# Prepare data for plotting
df_long <- df %>%
  select(prob_heads_to_heads, prob_tails_to_tails) %>%
  pivot_longer(
    cols = c(prob_heads_to_heads, prob_tails_to_tails),
    names_to = "starting_side",
    values_to = "probability"
  ) %>%
  mutate(
    starting_side = recode(starting_side,
                           prob_heads_to_heads = "Heads Up",
                           prob_tails_to_tails = "Tails Up")
  )

df_long %>%
  group_by(starting_side) %>%
  summarise(mean_prob = mean(probability, na.rm = TRUE),
            sd_prob = sd(probability, na.rm = TRUE)) %>%
  print()

t.test(probability ~ starting_side, data = df_long)
```

A violin plot (Figure 4) shows the distribution of these probabilities:

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Violin plot of probabilities by starting side
ggplot(df_long, aes(x = starting_side, y = probability, fill = starting_side)) +
  geom_violin(trim = FALSE, alpha = 0.8, adjust = 0.75) +
  geom_boxplot(width = 0.1, fill = "white", color = "black", outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1) +
  scale_fill_manual(values = c(viridis(5)[1], viridis(5)[5])) +
  labs(
    title = "Probability of Landing on the Same Side by Starting Side",
    x = "Starting Side",
    y = "Probability"
  ) +
  theme_minimal() +
  theme(legend.position = "none")


```

*Figure 4: Violin plot of the probability of landing on the same side by starting side.*

Both distributions are centered around 0.508, with comparable spread, suggesting **no notable systematic difference** between starting heads-up or tails-up. Some outliers in each group do appear, which may reflect unique participant behaviors or chance fluctuations.

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify outliers by starting side
starting_side_outliers <- df_long %>%
  group_by(starting_side) %>%
  filter(probability > mean(probability) + 2 * sd(probability) |
           probability < mean(probability) - 2 * sd(probability))

print(starting_side_outliers)
```

**Summary of EDA Findings**

-   **Slight Overall Bias**: The mean probability of landing on the same side is 0.508, slightly above 0.5, indicating a modest but statistically significant bias.

-   **Participant Variability**: A higher mean (0.510) and greater spread among participants highlight the importance of participant-specific effects. The outliers indicate certain participants might be flipping coins in a non-random manner.

-   **Minimal Coin Influence**: Coin-level probabilities are tightly clustered around 0.5, suggesting coin characteristics may not play a major role ompared to participant influences ---at least in this aggregated dataset.

-   **Starting Side**: Heads-up or tails-up leads to virtually the same probability (0.508), indicating little difference in bias by orientation.

These observations will guide the model-building phase. In particular, **participant effects** seem important, whereas coin effects appear weaker. Although starting side does not show a strong effect overall, we may still retain it in our models to capture any subtle differences.

#### **3. Analysis**

Building upon the insights from our EDA, we proceed to model the probability of a coin landing on the same side using generalized linear models (GLMs). Given the binary nature of the outcome (landing on the same side or not), logistic regression is an appropriate choice. We begin with a simple model and later incorporate hierarchical structures to account for variability.

##### 3.1 Simple Logistic Regression Model

As a first step, we fit the simplest possible logistic model, treating **all flips** (aggregated in `df`) as independent Bernoulli trials with a single intercept term. Conceptually, this model estimates a single probability \$p\$ that a flip lands heads, irrespective of participant or coin. Though extremely simplistic, it provides a baseline for more complex models.

This first model estimates a single probability $p = P(Y = 1)$, where $Y$ represents a coin landing heads up after starting heads up. The model is expressed as: \$ \log \left( \frac{p}{1 - p} \right) = \beta\_0\$ where $\beta_0$ is the intercept, representing the log-odds of the event.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Fit a simple logistic regression model
model_simple <- glm(cbind(heads_heads, N_start_heads_up - heads_heads) ~ 1, family = binomial, data = df)
summary(model_simple)
```

**Model Output**

The estimated coefficient and associated statistics are: \$ \hat{\beta}\_0 = 0.0314, \quad \text{SE}(\hat{\beta}\_0) = 0.0048, \quad z = \frac{\hat{\beta}_0}{\text{SE}(\hat{\beta}_0)} = 6.558, \quad p \< 0.001 \$

The intercept is statistically significant (\$ p \< 0.001 \$), indicating that the probability deviates from 0.5.

**Probability Estimate**

The probability of a coin landing heads up after starting heads up is obtained by applying the inverse logit function: \$\hat{p} = \frac{\exp(\hat{\beta}_0)}{1 + \exp(\hat{\beta}_0)} = \frac{\exp(0.0314)}{1 + \exp(0.0314)} \approx 0.508 \$

This result suggests a slight bias toward coins landing on the same side they started.

**Model Fit**

-   Null Deviance: 284.28
-   Residual Deviance: 284.28
-   AIC: 1739.6

The residual deviance equals the null deviance since no predictors were included, and the AIC provides a benchmark for model comparisons.

**Interpretation**

The estimated probability, \$\hat{p} \approx 0.508 \$, suggests a slight bias toward coins landing on the same side they started. This deviation is statistically significant, as indicated by the z-statistic and p-value. While this model captures the overall probability, it assumes that all flips are independent and identically distributed Bernoulli trials, ignoring potential variability due to participant effects, coin characteristics, or starting orientation. Further modeling will incorporate these factors to capture hierarchical structures and dependencies.


## **3.2 Incorporating Hierarchical Structures**

The simple logistic regression model provided a useful baseline, estimating an overall bias ($\hat{p} \approx 0.508$) toward coins landing on the same side. However, it assumes all flips are independent and identically distributed, ignoring:
- Participant-specific flipping styles.
- Coin-specific physical characteristics.

To address these issues, we fit hierarchical models using **generalized linear mixed models (GLMMs)**. These models account for variability at different levels, starting with participants and then considering coins nested within participants.

### **Model 1: Random Intercepts for Participants Only**

#### **Model Specification**

We first fit a GLMM that includes a random intercept for participants. This model captures variability in flipping outcomes across participants without considering coin-specific effects. The model is expressed as:
$$
\log \left( \frac{p_{ik}}{1 - p_{ik}} \right) = \beta_0 + \gamma_i
$$
where:
- $p_{ik}$: Probability of landing on the same side for the $k$-th flip by participant $i$.
- $\beta_0$: Fixed effect intercept, representing the overall log-odds across all participants.
- $\gamma_i$: Random effect for participant $i$, capturing variability in flipping styles.

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Load necessary library
library(lme4)

# Fit a mixed-effects logistic regression model with random intercepts for participants
glmm_participants <- glmer(cbind(total_same_side, total_flips - total_same_side) ~ 1 + 
                             (1 | person),
                           family = binomial, data = df)

# Summarize the model
summary(glmm_participants)
```

### **Model Results**

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Extract model summary statistics
library(broom.mixed)
fixed_effects_participants <- tidy(glmm_participants, effects = "fixed")
random_effects_participants <- tidy(glmm_participants, effects = "ran_pars")

# Display fixed and random effects
print(fixed_effects_participants)
print(random_effects_participants)
```
### **Results and Interpretation**

#### **Fixed Effect (\(\beta_0\)):**
The intercept (\(\beta_0 = 0.039884\)) represents the average log-odds of landing on the same side across all participants. Transforming this into a probability:
$$
\hat{p} = \frac{\exp(0.039884)}{1 + \exp(0.039884)} \approx 0.51
$$
This suggests a small but statistically significant bias (\(p < 0.001\)) toward coins landing on the same side (\(51\%\)).

#### **Random Effect Variance (\(\sigma_{\gamma}^2\)):**
The participant-specific random intercepts have a variance of \(\sigma_{\gamma}^2 = 0.003917\), corresponding to a standard deviation of \(\sigma_\gamma = 0.06258\). This indicates that while flipping styles vary between participants, the variability is relatively small compared to the overall scale of the fixed effect.

#### **Model Fit:**
The AIC of 1967.4 and log-likelihood of -981.7 provide benchmarks for comparison with more complex models.

#### **Limitations and Motivation for Next Model**
While this model captures participant-level variability, it assumes that all coins behave identically, which is likely unrealistic given differences in physical properties (e.g., weight, size, and material). Moreover, each coin is specific to a participant, introducing a nested structure in the data. Ignoring this structure may lead to an incomplete understanding of variability, as both participant-level effects (\(\sigma_{\gamma}^2\)) and coin-level effects (\(\sigma_{\delta(j)}^2\)) could contribute to the outcomes.

To better capture this nested structure and disentangle participant and coin-specific variability, we extend the model to include random intercepts for both participants and coins.

---

### **Model 2: Random Intercepts for Participants and Coins Nested Within Participants**

#### **Model Specification**
This extended model accounts for both participant-specific and coin-specific variability by including coins as random effects nested within participants. The model is expressed as:
$$
\log \left( \frac{p_{ijk}}{1 - p_{ijk}} \right) = \beta_0 + \gamma_i + \delta_{j(i)}
$$
where:
- \(\beta_0\): Fixed effect intercept, representing the overall log-odds of landing on the same side,
- \(\gamma_i\): Random effect for participant \(i\), capturing variability in flipping styles,
- \(\delta_{j(i)}\): Random effect for coin \(j\), nested within participant \(i\), capturing variability between coins flipped by the same participant.

This extension allows us to quantify the contribution of coin-specific variability relative to participant-specific variability, addressing the limitations of the first model and providing a more accurate representation of the data structure.

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Fit a mixed-effects logistic regression model with nested random intercepts
glmm_nested <- glmer(cbind(total_same_side, total_flips - total_same_side) ~ 1 + 
                      (1 | person/coin),
                    family = binomial, data = df)

# Summarize the model
summary(glmm_nested)
```

### **Model Results**

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Extract model summary statistics
fixed_effects_nested <- tidy(glmm_nested, effects = "fixed")
random_effects_nested <- tidy(glmm_nested, effects = "ran_pars")

# Display fixed and random effects
print(fixed_effects_nested)
print(random_effects_nested)
```
### **Results and Interpretation**
//maybe this is a bit repetitive//

The results are as follows:

- **Fixed Effect (\(\beta_0\)):**
    - The fixed intercept (\(\beta_0 = 0.038513\)) represents the average **log-odds** of landing on the same side across all participants and coins. Converting this to a probability:
      $$
      \hat{p} = \frac{\exp(0.038513)}{1 + \exp(0.038513)} \approx 0.51
      $$
      This suggests a slight but statistically significant bias (\(p < 0.001\)) toward coins landing on the same side (\(51\%\)).

- **Random Effect Variances:**
    - **Participant Variability (\(\sigma_{\gamma}^2\)):**
        - The participant-specific random intercepts have a variance of \(\sigma_{\gamma}^2 = 0.003631\), corresponding to a standard deviation of \(\sigma_\gamma = 0.06026\). This indicates that differences in flipping styles between participants are the primary source of variability.
    - **Coin Variability Nested Within Participants (\(\sigma_{\delta(j)}^2\)):**
        - The variance for coins nested within participants is \(\sigma_{\delta(j)}^2 = 0.000844\), with a standard deviation of \(\sigma_{\delta(j)} = 0.02905\). This reflects some additional variability due to individual coins, though it is smaller compared to participant-level variability.

- **Model Fit:**
    - The AIC of 1960.2 and log-likelihood of -977.1 indicate a slight improvement in model fit compared to Model 1 (AIC = 1967.4, log-likelihood = -981.7). This suggests that including coin-specific variability improves the model's explanatory power, though the improvement is modest.

#### **Key Insights:**
- **Dominance of Participant Effects:** The variability attributable to participants (\(\sigma_{\gamma}^2\)) is substantially larger than the variability attributable to coins (\(\sigma_{\delta(j)}^2\)), suggesting that flipping outcomes are primarily influenced by participant-specific behavior rather than coin-specific characteristics.
- **Hierarchical Structure:** By accounting for coins nested within participants, this model provides a more accurate representation of the data's structure, successfully partitioning variability at both levels.

This model enhances the understanding of flipping outcomes by capturing both participant and coin-level effects, confirming that participant-level variability is the dominant factor.

---
### **Comparison of Models**

To evaluate the importance of including hierarchical structures, we compare all models: the simple logistic regression model, the participants-only random effects model, and the participants-and-nested-coins random effects model. We use likelihood ratio tests, AIC, and BIC values to assess the models.

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Compare all three models using AIC, BIC, and log-likelihood
comparison <- data.frame(
  Model = c("Simple Logistic Regression", "Participants Only", "Participants and Nested Coins"),
  LogLikelihood = c(logLik(model_simple), logLik(glmm_participants), logLik(glmm_nested)),
  AIC = c(AIC(model_simple), AIC(glmm_participants), AIC(glmm_nested)),
  BIC = c(BIC(model_simple), BIC(glmm_participants), BIC(glmm_nested))
)

print(comparison)
```
## Results and Interpretation

### Simple Logistic Regression

The Simple Logistic Regression model has the highest log-likelihood (\(-868.8\)) and the lowest AIC (\(1739.6\)) and BIC (\(1742.9\)). This is because it assumes all flips are independent and identically distributed, which simplifies the model. However, this simplicity comes at the cost of ignoring the hierarchical structure of the data, such as variability between participants and coins.

### Participants-Only Model

Adding random intercepts for participants reduces the log-likelihood (\(-981.7\)) and increases both AIC (\(1967.4\)) and BIC (\(1974.1\)) compared to the simple model. This indicates that accounting for participant-specific variability improves the model fit but also adds complexity, as evidenced by the higher AIC and BIC values.  
This model highlights the importance of participant-level effects, but it assumes that all coins behave identically, which may not fully capture the variability in the data.

### Participants and Nested Coins Model

Adding nested coin effects further improves the model, with a log-likelihood of \(-977.1\), AIC of \(1960.2\), and BIC of \(1970.3\). The reductions in AIC and BIC compared to the Participants-Only model suggest that including coin-specific effects improves the fit while managing complexity better.

### Likelihood Ratio Tests

We use likelihood ratio tests (LRTs) to formally compare the models:

```{r}
# Perform likelihood ratio tests for nested models
anova(model_simple, glmm_participants, glmm_nested, test = "Chisq")
```
## Simple vs. Participants Only

The significant likelihood ratio test (\(p < 0.001\)) indicates that the participants-only model provides a much better fit to the data than the simple model. This improvement reflects the importance of capturing participant-specific variability.

## Participants Only vs. Participants and Nested Coins

The likelihood ratio test (\(p = 0.0025\)) supports the inclusion of nested coin effects, confirming that the additional complexity is justified.

## Key Takeaways

- **Simple Model**: Provides a good baseline but ignores variability due to participants and coins, which limits its explanatory power.
- **Participants-Only Model**: Captures participant-specific variability and significantly improves the fit over the simple model.
- **Participants and Nested Coins Model**: Further improves the model by accounting for coin-specific effects, although the improvement is smaller compared to the step from the simple model to the participants-only model. Participant-level variability remains the dominant factor.

While the participants-and-nested-coins model is the best-fitting model, the coin-level variability (\(\sigma_{\delta(j)}^2\)) is relatively small compared to participant-level variability (\(\sigma_{\gamma}^2\)). This suggests that flipping outcomes are primarily driven by participant-specific behavior rather than coin-specific characteristics.

## Conclusion

The participants-and-nested-coins model provides the most accurate representation of the data, as it accounts for both participant and coin-specific variability. However, the relatively small coin-level variance suggests that participants are the primary source of variability in flipping outcomes. These findings highlight the importance of modeling hierarchical structures to capture the complexity of the data.


## **Analysis of Learning Effects and Influence of Recent Flips**

Building on the previous analysis, we now investigate whether participants exhibit **learning effects** (i.e., improving flipping consistency over time) and whether **recent flips influence the outcome** of the current flip. These analyses allow us to better understand behavioral trends and potential dependencies in flipping outcomes.

---

### **Learning Effects**

#### **Objective**

To examine whether participants' probabilities of flipping a coin that lands on the same side improve over time, we analyze the relationship between the **flip sequence** (indexed by `flip_index`) and the probability of landing on the same side.

#### **Approach**

1. We include a sequential variable `flip_index` representing the order of flips for each participant.
2. We model learning effects using a generalized linear mixed model (GLMM) with `flip_index` as a fixed effect and random intercepts for participants and coins.

#### **Code and Results**

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Load the new dataset
df_time <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/df-time.csv")
# Ensure factors are properly set
df_time <- df_time %>%
  mutate(
    person = factor(person),
    coin = factor(coin),
    toss_start = factor(toss_start),
    toss_end = factor(toss_end)
  )

df_time <- df_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    lag_1 = lag(toss_end, 1),  # Outcome of the previous flip
    lag_2 = lag(toss_end, 2),  # Outcome of two flips ago
    lag_3 = lag(toss_end, 3)   # Outcome of three flips ago
  ) %>%
  ungroup()
# Check the first few rows
head(df_time)

# Summarize the distribution of lagged variables
summary(df_time[, c("lag_1", "lag_2", "lag_3")])

# Fit a logistic regression model to test the influence of recent flips
model_recent_flips <- glm(
  toss_end ~ lag_1 + lag_2 + lag_3, 
  family = binomial, 
  data = df_time
)

# Summarize the model
summary(model_recent_flips)
```
The initial analysis of recent flips revealed that only the most immediate prior outcome (lag 1) significantly influences the current flip, suggesting a short-term dependency. However, the effects of outcomes from two or three flips ago (lag 2 and lag 3) were not significant, indicating that dependencies diminish quickly over time.

While this analysis provides insight into short-term influences, it does not account for potential learning effects—the possibility that participants improve their consistency or develop systematic flipping patterns over time. Additionally, the influence of lag 1 may vary across participants, and the interaction between learning effects and recent flips could reveal more complex behavioral dynamics.

To address these gaps, we extend the analysis with the following goals:

### Learning Effects Over Time:
- Investigate whether participants' probabilities of flipping a coin that lands on the same side improve or change over the course of the experiment.

### Random Slopes for Recent Flips:
- Test whether the effect of the most recent flip (lag 1) varies across participants, capturing individual differences in short-term dependencies.

### Interactions Between Learning and Lag Effects:
- Examine whether the influence of recent flips (lag 1) evolves over time, potentially indicating changes in behavior or flipping strategy.

These extensions will allow us to capture more nuanced patterns of participant behavior and dependencies, providing a comprehensive understanding of the factors influencing flipping outcomes.

### Proposed Models

#### Learning Effects Model:
Add flip_index as a fixed effect to assess trends over time: 

logit(p_ijk) = β0 + β1 * flip_index_ij + γi + δj(i)

#### Random Slopes for Lag Effects:
Allow the effect of lag 1 to vary across participants: 

logit(p_ijk) = β0 + β1 * lag1 + γi + δj(i) + u1i * lag1

#### Interaction Model:
Include an interaction term between flip_index and lag 1: 

logit(p_ijk) = β0 + β1 * flip_index_ij + β2 * lag1 + β3 * (flip_index * lag1) + γi + δj(i)

Each of these models will help clarify the relationship between time, recent outcomes, and individual variability in flipping behavior. The results will also guide further interpretation of potential behavioral patterns or biases in flipping outcomes.

```{r}
# Load necessary library
library(lme4)

# Create sequential flip index for each participant
df_time <- df_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    flip_index = row_number()  # Sequential index for each flip within a sequence
  ) %>%
  ungroup()


model_learning <- glmer(
  toss_end ~ flip_index + (1 | person) + (1 | person/coin),  # Random effects for participants and coins nested within participants
  family = binomial,
  data = df_time
)

# Summary of the model
summary(model_learning)
```


```{r}
# Random Slopes for Lag 1
model_random_slopes <- glmer(
  toss_end ~ lag_1 + (lag_1 | person) + (1 | person/coin),  # Random slope for lag_1 by participants
  family = binomial,
  data = df_time
)

# Summary of the model
summary(model_random_slopes)

```

```{r}
# Interaction Model
model_interaction <- glmer(
  toss_end ~ flip_index * lag_1 + (1 | person) + (1 | person/coin),  # Interaction term between flip_index and lag_1
  family = binomial,
  data = df_time
)

# Summary of the model
summary(model_interaction)
```

```{r}
# Model Comparison
anova(model_learning, model_random_slopes, model_interaction, test = "Chisq")
library(DHARMa)
# Diagnostics for the interaction model
simulateResiduals(model_interaction)
# Learning effects over time
library(ggplot2)
ggplot(df_time, aes(x = flip_index, y = as.numeric(toss_end == "h"))) +
  geom_smooth(method = "loess", color = "blue") +
  labs(
    title = "Learning Effects Over Time",
    x = "Flip Index",
    y = "Probability of Heads"
  ) +
  theme_minimal()

# Interaction effects
interaction_effects <- df_time %>%
  group_by(flip_index, lag_1) %>%
  summarise(prob_heads = mean(toss_end == "h", na.rm = TRUE), .groups = "drop")

ggplot(interaction_effects, aes(x = flip_index, y = prob_heads, color = lag_1)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Interaction Between Flip Index and Recent Flip (Lag 1)",
    x = "Flip Index",
    y = "Probability of Heads",
    color = "Lag 1 Outcome"
  ) +
  theme_minimal()

```

```{r}
library(dplyr)

# Define streaks
df_time <- df_time %>%
  group_by(person, sequence_id) %>%
  mutate(
    streak = cumsum(c(1, diff(toss_end == "h") != 0))  # Increment streak when toss changes
  ) %>%
  ungroup()

# Count streak lengths
streak_lengths <- df_time %>%
  group_by(person, streak) %>%
  summarise(
    streak_length = n(),  # Count streak length
    toss_outcome = first(toss_end)  # Determine streak type (heads/tails)
  ) %>%
  ungroup()

# Visualize streak distribution
streak_distribution <- streak_lengths %>%
  group_by(streak_length, toss_outcome) %>%
  summarise(
    count = n()
  )

ggplot(streak_distribution, aes(x = streak_length, y = count, fill = toss_outcome)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_x_continuous(limits = c(1, 10)) +
  labs(
    title = "Streak Length Distribution",
    x = "Streak Length",
    y = "Count",
    fill = "Toss Outcome"
  ) +
  theme_minimal()
```
```{r}
# Compute transition probabilities
transition_probs <- df_time %>%
  group_by(person) %>%
  summarise(
    P_heads_given_heads = mean(toss_end == "h" & lag_1 == "h", na.rm = TRUE) / mean(lag_1 == "h", na.rm = TRUE),
    P_heads_given_tails = mean(toss_end == "h" & lag_1 == "t", na.rm = TRUE) / mean(lag_1 == "t", na.rm = TRUE)
  )

print(transition_probs)

# Compare first-order transitions
ggplot(transition_probs, aes(x = factor(person))) +
  geom_bar(aes(y = P_heads_given_heads, fill = "P(Heads | Heads)"), stat = "identity", position = "dodge") +
  geom_bar(aes(y = P_heads_given_tails, fill = "P(Heads | Tails)"), stat = "identity", position = "dodge") +
  labs(
    title = "Transition Probabilities by Person",
    x = "Participant",
    y = "Probability",
    fill = "Transition Type"
  ) +
  theme_minimal()
```
```{r}
# Calculate cumulative probability
cumulative_prob <- df_time %>%
  group_by(person) %>%
  mutate(
    prop_heads_so_far = cumsum(toss_end == "h") / row_number()
  ) %>%
  ungroup()

# Plot cumulative probability
ggplot(cumulative_prob, aes(x = toss_number, y = prop_heads_so_far, color = person)) +
  geom_line() +
  labs(
    title = "Cumulative Probability of Heads Over Tosses",
    x = "Toss Number",
    y = "Cumulative Probability of Heads",
    color = "Participant"
  ) +
  theme_minimal()
```

```{r}
# Compare first 50 and last 50 flips in each sequence
sequence_comparison <- df_time %>%
  group_by(person, sequence_id) %>%
  summarise(
    first_50_prob = mean(toss_end[1:min(50, n())] == "h", na.rm = TRUE),  # Handle cases with fewer than 50 flips
    last_50_prob = mean(toss_end[max(1, n() - 49):n()] == "h", na.rm = TRUE)  # Handle cases with fewer than 50 flips
  ) %>%
  ungroup()

# Visualize sequence performance
ggplot(sequence_comparison, aes(x = first_50_prob, y = last_50_prob, color = person)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(
    title = "First 50 vs Last 50 Tosses: Sequence Comparison",
    x = "First 50 Tosses (Probability of Heads)",
    y = "Last 50 Tosses (Probability of Heads)",
    color = "Participant"
  ) +
  theme_minimal()


```

