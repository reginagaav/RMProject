---
title: "Regression Methods Project"
format: html
header-includes: 
  - \usepackage{xcolor}
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{bm}
df_agg-engine: xelatex
---


#### **1. Introduction and Exploratory Data Analysis**

Our analysis begins with studying the patterns in the data to inform modeling. 

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Load necessary libraries
library(tidyverse)
library(glue)
library(viridis)
library(ggplot2)
library(dplyr)
library(performance)     # For check_model, etc.
library(patchwork)       # For side-by-side plots
library(lme4)            # For GLMM
library(broom)
library(broom.mixed)     # Tidy for mixed models
library(car)             # For VIF
library(lattice)         # For random-effects dotplot

# Read the aggregated dataset
df_agg <- read_csv("/Users/graceaverell/Desktop/EPFL/regression methods/coin data/analyses/data-agg.csv") %>%
  mutate(
    person = factor(person),
    coin = factor(coin)
  )

#df_agg <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/data-agg.csv") %>%
#  mutate(
#    person = factor(person),
#    coin = factor(coin)
#  )

# Read the time-resolved dataset
df_agg_time <- read_csv("/Users/graceaverell/Desktop/EPFL/regression methods/coin data/analyses/df-time.csv") %>%
  mutate(
    person = factor(person),
    coin = factor(coin),
    toss_start = factor(toss_start),
    toss_end = factor(toss_end)
  ) %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    lag_1 = lag(toss_end, 1),  # Outcome of the previous flip
    lag_2 = lag(toss_end, 2),  # Outcome of two flips ago
    lag_3 = lag(toss_end, 3)   # Outcome of three flips ago
  ) %>%
  ungroup() %>%
  filter(!is.na(lag_1) & !is.na(lag_2) & !is.na(lag_3))  # Remove NA rows for lags

#df_agg_time <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/df_agg-time.csv") %>%
#  mutate(
#    person     = factor(person),
#    coin       = factor(coin),
#    toss_start = factor(toss_start),
#    toss_end   = factor(toss_end)
#  ) %>%
#  arrange(person, sequence_id, toss_number) %>%
#  group_by(person, sequence_id) %>%
#  mutate(
#    lag_1 = lag(toss_end, 1),
#    lag_2 = lag(toss_end, 2),
#    lag_3 = lag(toss_end, 3)
#  ) %>%
#  ungroup()

# Check resulting data frame
head(df_agg_time)

dim(df_agg_time)


```

##### **1.1. EDA**

**Overall Probability of Landing on the Same Side**

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate flips where the coin landed on the opposite side
df_agg <- df_agg %>%
  mutate(
    heads_tails = N_start_heads_up - heads_heads,
    tails_tails = N_start_tails_up - tails_heads
  )

# Calculate total flips and probabilities
df_agg <- df_agg %>%
  mutate(
    total_flips = N_start_heads_up + N_start_tails_up,
    total_same_side = heads_heads + tails_tails,
    prob_same_side = total_same_side / total_flips,
    prob_heads_to_heads = heads_heads / N_start_heads_up,
    prob_tails_to_tails = tails_tails / N_start_tails_up
  )

# Summary statistics for probability of landing on the same side}
summary_stats <- df_agg %>%
  summarise(
    mean_prob_same_side = mean(prob_same_side, na.rm = TRUE),
    median_prob_same_side = median(prob_same_side, na.rm = TRUE),
    sd_prob_same_side = sd(prob_same_side, na.rm = TRUE)
  )

print(summary_stats)
```

```{r, message=FALSE, warning=FALSE}
#| echo: false
# t test against p=0.5 
t.test(df_agg$prob_same_side, mu = 0.5, alternative = "two.sided")
```

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side

fig1 <- ggplot(df_agg, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[2]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig1.png", plot = fig1, width = 8, height = 6, dpi = 300)
```

**Participant-Level Analysis**

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate participant-level probabilities
participant_probs <- df_agg %>%
  group_by(person) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at participant level
participant_summary <- participant_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(participant_summary)

```

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side by participant
fig2 <- ggplot(participant_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[3]) +
  labs(
    title = "Probability of Landing on the Same Side by Participant",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig2.png", plot = fig2, width = 8, height = 6, dpi = 300)
```

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Identify participants with extreme probabilities
participant_outliers <- participant_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(participant_outliers)

```

**Coin-Level Analysis**

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate coin-level probabilities
coin_probs <- df_agg %>%
  group_by(coin) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at coin level
coin_summary <- coin_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(coin_summary)

```

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities by coin
fig3 <- ggplot(coin_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[4]) +
  labs(
    title = "Probability of Landing on the Same Side by Coin",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig3.png", plot = fig3, width = 8, height = 6, dpi = 300)
```

```{r}
#| echo: false
# Merge participant and coin histograms side by side
fig_merged <- fig2 + fig3 + 
  plot_layout(ncol = 2) & 
  theme(plot.title = element_text(size = 12))

ggsave("fig_merged.png", plot = fig_merged, width = 10, height = 5, dpi = 300)

fig_merged

```

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify coin outliers
coin_outliers <- coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(coin_outliers)
```

```{r,message=FALSE,warning=FALSE}
# Calculate probabilities for person/coin combinations
person_coin_probs <- df_agg %>%
  group_by(person, coin) %>%
  summarise(prob_same_side = mean(prob_same_side, na.rm = TRUE), .groups = "drop")

# Identify person/coin combination outliers
person_coin_outliers <- person_coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(person_coin_outliers)
```

**Effect of Starting Side**

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Compare probabilities based on starting side
starting_side_probs <- df_agg %>%
  summarise(
    mean_prob_heads_to_heads = mean(prob_heads_to_heads, na.rm = TRUE),
    mean_prob_tails_to_tails = mean(prob_tails_to_tails, na.rm = TRUE),
    sd_prob_heads_to_heads = sd(prob_heads_to_heads, na.rm = TRUE),
    sd_prob_tails_to_tails = sd(prob_tails_to_tails, na.rm = TRUE)
  )

print(starting_side_probs)

```

```{r,message=FALSE, warning=FALSE}
#| echo: false
# Prepare data for plotting
df_agg_long <- df_agg %>%
  select(prob_heads_to_heads, prob_tails_to_tails) %>%
  pivot_longer(
    cols = c(prob_heads_to_heads, prob_tails_to_tails),
    names_to = "starting_side",
    values_to = "probability"
  ) %>%
  mutate(
    starting_side = recode(starting_side,
                           prob_heads_to_heads = "Heads Up",
                           prob_tails_to_tails = "Tails Up")
  )

df_agg_long %>%
  group_by(starting_side) %>%
  summarise(mean_prob = mean(probability, na.rm = TRUE),
            sd_prob = sd(probability, na.rm = TRUE)) %>%
  print()

t.test(probability ~ starting_side, data = df_agg_long)
```

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Violin plot of probabilities by starting side
fig4 <- ggplot(df_agg_long, aes(x = starting_side, y = probability, fill = starting_side)) +
  geom_violin(trim = FALSE, alpha = 0.8, adjust = 0.75) +
  geom_boxplot(width = 0.1, fill = "white", color = "black", outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1) +
  scale_fill_manual(values = c(viridis(5)[1], viridis(5)[5])) +
  labs(
    title = "Probability of Landing on the Same Side by Starting Side",
    x = "Starting Side",
    y = "Probability"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

ggsave("fig4.png", plot = fig4, width = 8, height = 6, dpi = 300)
```

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify outliers by starting side
starting_side_outliers <- df_agg_long %>%
  group_by(starting_side) %>%
  filter(probability > mean(probability) + 2 * sd(probability) |
           probability < mean(probability) - 2 * sd(probability))

print(starting_side_outliers)
```

#### **2. Analysis**

##### 2.1 Simple Logistic Regression Model

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Fit the simplest possible logistic model
model_1 <- glm(
  cbind(heads_heads, N_start_heads_up - heads_heads) ~ 1,
  family = binomial,
  data = df_agg
)

# Print summary
summary(model_1)

# Model diagnostics 
check_model(model_1)

```

##### 2.2 Random Intercepts for Participants Only

```{r, message=FALSE, warning=FALSE}
#| echo: true
# Fit a mixed-effects logistic regression model with random intercepts for participants
model_2 <- glmer(cbind(total_same_side, total_flips - total_same_side) ~ 1 + 
                             (1 | person),
                           family = binomial, data = df_agg)

# Print summary
summary(model_2)

# Model diagnostics
check_model(model_2)
```

```{r, message=FALSE, warning=FALSE}
#| echo: true

# extract fixed and random effects
fixed_effects_participants <- tidy(model_2, effects = "fixed")
random_effects_participants <- tidy(model_2, effects = "ran_pars")

fixed_effects_participants
random_effects_participants

```

##### 2.3 Random Intercepts for Participants and Coins Nested Within Participants

```{r, message=FALSE, warning=FALSE}
#| echo: true
# Fit a mixed-effects logistic regression model with nested random intercepts
model_3 <- glmer(cbind(total_same_side, total_flips - total_same_side) ~ 1 + 
                      (1 | person/coin),
                    family = binomial, data = df_agg)
# Print Summary
summary(model_3)

# Model diagnostics
check_model(model_3)
```


```{r, message=FALSE, warning=FALSE}
#| echo: true

# extract fixed and random effects
fixed_effects_nested <- tidy(model_3, effects = "fixed")
random_effects_nested <- tidy(model_3, effects = "ran_pars")

fixed_effects_nested
random_effects_nested

```
#### Comparison of Models 1,2 and 3

```{r, message=FALSE, warning=FALSE}
#| echo: true
# Summaries of AIC, BIC, logLik, deviance
model_comp <- rbind(
  data.frame(
    Model       = "Model 1: Simple Logistic",
    AIC         = AIC(model_1),
    BIC         = BIC(model_1),
    logLik      = as.numeric(logLik(model_1)),
    Deviance    = deviance(model_1)
  ),
  data.frame(
    Model       = "Model 2: Participants Only",
    AIC         = AIC(model_2),
    BIC         = BIC(model_2),
    logLik      = as.numeric(logLik(model_2)),
    Deviance    = deviance(model_2)
  ),
  data.frame(
    Model       = "Model 3: Participants + Nested Coins",
    AIC         = AIC(model_3),
    BIC         = BIC(model_3),
    logLik      = as.numeric(logLik(model_3)),
    Deviance    = deviance(model_3)
  )
)

model_comp

```

We use likelihood ratio tests (LRTs) to formally compare the models:

```{r, message=FALSE, warning=FALSE}
#| echo: true

anova(model_1, model_2, model_3, test = "Chisq")

```


```{r, message=FALSE, warning=FALSE}
#| echo: true
# Comparing fixed effects

# For model_1 (GLM):
fixef_1 <- tidy(model_1) %>%
  select(term, estimate, std.error, statistic, p.value) %>%
  mutate(Model = "Model 1")

# For model_2 (mixed-effects):
fixef_2 <- tidy(model_2, effects = "fixed") %>%
  select(term, estimate, std.error, statistic, p.value) %>%
  mutate(Model = "Model 2")

# For model_3 (mixed-effects):
fixef_3 <- tidy(model_3, effects = "fixed") %>%
  select(term, estimate, std.error, statistic, p.value) %>%
  mutate(Model = "Model 3")

# Now all three data frames have the same columns and can be row-bound
fixed_all <- rbind(fixef_1, fixef_2, fixef_3)
fixed_all


```

```{r, message=FALSE, warning=FALSE}
#| echo: true

#Comparing random effects
ranef_2 <- tidy(model_2, effects = "ran_pars") %>% mutate(Model = "Model 2")
ranef_3 <- tidy(model_3, effects = "ran_pars") %>% mutate(Model = "Model 3")

rbind(ranef_2, ranef_3)

```
##### 2.4 Analysis of Time Resolved Data

###### 2.4.1 Logistic Models with Lagged Covariates
```{r, message=FALSE, warning=FALSE}
#| echo: true
lag_models <- list(
  lag1 = glm(toss_end ~ lag_1, family=binomial, data=df_agg_time),
  lag2 = glm(toss_end ~ lag_1 + lag_2, family=binomial, data=df_agg_time),
  lag3 = glm(toss_end ~ lag_1 + lag_2 + lag_3, family=binomial, data=df_agg_time)
)

# Compare models using AIC and Likelihood Ratio Tests
AIC(lag_models$lag1, lag_models$lag2, lag_models$lag3)
anova(lag_models$lag1, lag_models$lag2, test="Chisq")
anova(lag_models$lag2, lag_models$lag3, test="Chisq")

```

###### 2.4.2 Markov Chain Analysis

```{r, message=FALSE, warning=FALSE}
#| echo: true
transition_table <- table(df_agg_time$lag_1, df_agg_time$toss_end)
transition_table
chisq.test(transition_table)

transition_plot_df <- df_agg_time %>%
  filter(!is.na(lag_1)) %>%
  mutate(
    prev_flip = factor(lag_1, levels = c("h", "t")),
    curr_flip = factor(toss_end, levels = c("h", "t"))
  ) %>%
  group_by(prev_flip, curr_flip) %>%
  tally() %>%
  group_by(prev_flip) %>%
  mutate(prob = n / sum(n)) %>%
  ungroup()

ggplot(transition_plot_df, aes(x = prev_flip, y = prob, fill = curr_flip)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Transition Probabilities (Markov Chain Analysis)",
    x = "Previous Flip Outcome",
    y = "Probability"
  ) +
  scale_fill_viridis_d(name = "Current Flip") +
  theme_minimal()

```

###### 2.4.3 Learning Effects Model

```{r, message=FALSE, warning=FALSE}
#| echo: true
df_agg_time <- df_agg_time %>%
  group_by(person, sequence_id) %>%
  mutate(flip_index = row_number()) %>%
  ungroup()

model_learning <- glm((toss_start == toss_end) ~ flip_index,
                      family=binomial,
                      data=df_agg_time)
summary(model_learning)

null_learning <- glm((toss_start == toss_end) ~ 1,
                     family=binomial,
                     data=df_agg_time)
anova(null_learning, model_learning, test="Chisq")

check_model(model_learning)

```
###### 2.4.4 Mixed-Effects Logistic Model

```{r, message=FALSE, warning=FALSE}
#| echo: true
df_agg_time <- df_agg_time %>%
  group_by(person, coin) %>%
  mutate(
    y = sum(toss_end == "h"),  # Successes
    m = n()                    # Total tosses
  ) %>%
  ungroup()

mixed_model <- glmer(cbind(y, m - y) ~ lag_1 + (1 | person/coin), family = binomial, data = df_agg_time)
null_mixed <- glmer(cbind(y, m - y) ~ 1 + (1 | person/coin), family = binomial, data = df_agg_time)

cat("\nMixed-Effects Logistic Model Summary:\n")
print(summary(mixed_model))
cat("\nLikelihood Ratio Test (Mixed vs Null):\n")
print(anova(null_mixed, mixed_model, test = "Chisq"))

dotplot(ranef(mixed_model), main = "Random Effects for Mixed Model")  # Random effects visualization

performance::check_model(mixed_model)  # Model diagnostics

```

###### 2.4.5 Binomial Approximation (WLS)

```{r, message=FALSE, warning=FALSE}
#| echo: true
binomial_data <- df_agg_time %>%
  group_by(person, coin) %>%
  summarise(
    total_flips = n(),
    total_success = sum(toss_start == toss_end),
    proportion_success = total_success / total_flips,
    weight = 4 * total_flips
  ) %>%
  ungroup()

wls_model <- lm(proportion_success ~ 1, weights = weight, data = binomial_data)

cat("\nWeighted Least Squares Model Summary:\n")
print(summary(wls_model))

# Residual diagnostics for WLS
binomial_data <- binomial_data %>%
  mutate(
    fitted_values = predict(wls_model),
    residuals = residuals(wls_model)
  )

ggplot(binomial_data, aes(x = fitted_values, y = residuals)) +
  geom_point(alpha = 0.5) +
  labs(title = "Residual Plot for WLS Model", x = "Fitted Values", y = "Residuals") +
  theme_minimal()

```

##### AIC Comparison Across Models

```{r, message=FALSE, warning=FALSE}
#| echo: true
aic_values <- data.frame(
  Model = c("Logistic Lag1", "Logistic Lag2", "Logistic Lag3", "Mixed Effects", "WLS"),
  AIC = c(
    AIC(logistic_models$lag1),
    AIC(logistic_models$lag2),
    AIC(logistic_models$lag3),
    AIC(mixed_model),
    AIC(wls_model)
  )
)

cat("\nAIC Comparison Across Models:\n")
print(aic_values)

ggplot(aic_values, aes(x = Model, y = AIC)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "AIC Comparison Across Models", x = "Model", y = "AIC") +
  theme_minimal()

```



#### info dump down here, will adapt to add to the report but not yet

## Results and Interpretation

### Simple Logistic Regression

The Simple Logistic Regression model has the highest log-likelihood (\(-868.8\)) and the lowest AIC (\(1739.6\)) and BIC (\(1742.9\)). This is because it assumes all flips are independent and identically distributed, which simplifies the model. However, this simplicity comes at the cost of ignoring the hierarchical structure of the data, such as variability between participants and coins.

### Participants-Only Model

Adding random intercepts for participants reduces the log-likelihood (\(-981.7\)) and increases both AIC (\(1967.4\)) and BIC (\(1974.1\)) compared to the simple model. This indicates that accounting for participant-specific variability improves the model fit but also adds complexity, as evidenced by the higher AIC and BIC values.  
This model highlights the importance of participant-level effects, but it assumes that all coins behave identically, which may not fully capture the variability in the data.

### Participants and Nested Coins Model

Adding nested coin effects further improves the model, with a log-likelihood of \(-977.1\), AIC of \(1960.2\), and BIC of \(1970.3\). The reductions in AIC and BIC compared to the Participants-Only model suggest that including coin-specific effects improves the fit while managing complexity better.



## Simple vs. Participants Only

The significant likelihood ratio test (\(p < 0.001\)) indicates that the participants-only model provides a much better fit to the data than the simple model. This improvement reflects the importance of capturing participant-specific variability.

## Participants Only vs. Participants and Nested Coins

The likelihood ratio test (\(p = 0.0025\)) supports the inclusion of nested coin effects, confirming that the additional complexity is justified.

## Key Takeaways

- **Simple Model**: Provides a good baseline but ignores variability due to participants and coins, which limits its explanatory power.
- **Participants-Only Model**: Captures participant-specific variability and significantly improves the fit over the simple model.
- **Participants and Nested Coins Model**: Further improves the model by accounting for coin-specific effects, although the improvement is smaller compared to the step from the simple model to the participants-only model. Participant-level variability remains the dominant factor.

While the participants-and-nested-coins model is the best-fitting model, the coin-level variability (\(\sigma_{\delta(j)}^2\)) is relatively small compared to participant-level variability (\(\sigma_{\gamma}^2\)). This suggests that flipping outcomes are primarily driven by participant-specific behavior rather than coin-specific characteristics.

## Conclusion

The participants-and-nested-coins model provides the most accurate representation of the data, as it accounts for both participant and coin-specific variability. However, the relatively small coin-level variance suggests that participants are the primary source of variability in flipping outcomes. These findings highlight the importance of modeling hierarchical structures to capture the complexity of the data.