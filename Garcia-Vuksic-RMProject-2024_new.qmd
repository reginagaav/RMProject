---
title: "Regression Methods Project"
format: html
header-includes:
  - \usepackage{xcolor}  
  - \usepackage{amsmath} 
  - \usepackage{amssymb} 
  - \usepackage{bm}      
pdf_agg-engine: xelatex      
---

#### **1. Introduction and Exploratory Data Analysis**

Our analysis begins with studying the patterns in the data to inform modeling. 

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Load necessary libraries
library(tidyverse)
library(glue)
library(viridis)
library(ggplot2)
library(dplyr)
library(performance)
library(patchwork)
library(lme4)

# Read the aggregated dataset
df_agg <- read_csv("/Users/graceaverell/Desktop/EPFL/regression methods/coin data/analyses/data-agg.csv") %>%
  mutate(
    person = factor(person),
    coin = factor(coin)
  )

#df_agg <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/data-agg.csv") %>%
#  mutate(
#    person = factor(person),
#    coin = factor(coin)
#  )

# Read the time-resolved dataset
df_agg_time <- read_csv("/Users/graceaverell/Desktop/EPFL/regression methods/coin data/analyses/df-time.csv") %>%
  mutate(
    person     = factor(person),
    coin       = factor(coin),
    toss_start = factor(toss_start),
    toss_end   = factor(toss_end)
  ) %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    lag_1 = lag(toss_end, 1),
    lag_2 = lag(toss_end, 2),
    lag_3 = lag(toss_end, 3)
  ) %>%
  ungroup()

#df_agg_time <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/df_agg-time.csv") %>%
#  mutate(
#    person     = factor(person),
#    coin       = factor(coin),
#    toss_start = factor(toss_start),
#    toss_end   = factor(toss_end)
#  ) %>%
#  arrange(person, sequence_id, toss_number) %>%
#  group_by(person, sequence_id) %>%
#  mutate(
#    lag_1 = lag(toss_end, 1),
#    lag_2 = lag(toss_end, 2),
#    lag_3 = lag(toss_end, 3)
#  ) %>%
#  ungroup()

# Check the first few rows
head(df_agg_time)

```

##### **1.1. EDA for Aggregated Data (df_agg)**

**Overall Probability of Landing on the Same Side**

To assess the overall bias, we first compute how often the coin ends on the same side it started.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate flips where the coin landed on the opposite side
df_agg <- df_agg %>%
  mutate(
    heads_tails = N_start_heads_up - heads_heads,
    tails_tails = N_start_tails_up - tails_heads
  )

# Calculate total flips and probabilities
df_agg <- df_agg %>%
  mutate(
    total_flips = N_start_heads_up + N_start_tails_up,
    total_same_side = heads_heads + tails_tails,
    prob_same_side = total_same_side / total_flips,
    prob_heads_to_heads = heads_heads / N_start_heads_up,
    prob_tails_to_tails = tails_tails / N_start_tails_up
  )

# Summary statistics for probability of landing on the same side}
summary_stats <- df_agg %>%
  summarise(
    mean_prob_same_side = mean(prob_same_side, na.rm = TRUE),
    median_prob_same_side = median(prob_same_side, na.rm = TRUE),
    sd_prob_same_side = sd(prob_same_side, na.rm = TRUE)
  )

print(summary_stats)
```

```{r, message=FALSE, warning=FALSE}
#| echo: false
t.test(df_agg$prob_same_side, mu = 0.5, alternative = "two.sided")
```

From these results, we find a **mean probability** of about 0.508, slightly exceeding 0.5. A one-sample t-test against 0.5 indicates a statistically significant difference ($p < 0.05$). We visualize the distribution of these probabilities in Figure 1.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side

fig1 <- ggplot(df_agg, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[2]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig1.png", plot = fig1, width = 8, height = 6, dpi = 300)
```

*Figure 1: Histogram of the probability of landing on the same side across all coins and participants.*


**Participant-Level Analysis**

Next, we examine how this probability varies by participant. 

We sum heads-up and tails-up flips by participant to obtain

$p_i = \frac{(\text{heads_heads})_i + (\text{tails_tails})_i}{(\text{total_flips})_i}$

where $(\text{heads_heads})_i$ is the total number of heads outcomes from heads-up starts for participant $i$, etc.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate participant-level probabilities
participant_probs <- df_agg %>%
  group_by(person) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at participant level
participant_summary <- participant_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(participant_summary)

```

The **mean participant-level probability** is around 0.510, slightly higher than the overall mean. This is illustrated in Figure 2.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side by participant
fig2 <- ggplot(participant_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[3]) +
  labs(
    title = "Probability of Landing on the Same Side by Participant",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig2.png", plot = fig2, width = 8, height = 6, dpi = 300)
```

*Figure 2: Histogram of Probability of Landing on the Same Side by Participant*

We identify outliers by checking which participants' probabilities lie beyond two standard deviations from the mean.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Identify participants with extreme probabilities
participant_outliers <- participant_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(participant_outliers)

```

**Coin-Level Analysis**

We then group flips by each *coin* to see whether some coins inherently land on the same side more frequently. Analogously, we compute

$q_j = \frac{(\text{heads_heads})_j + (\text{tails_tails})_j}{(\text{total_flips})_j}$

where $(\text{heads_heads})_j$ denotes the total number of heads outcomes from heads-up starts for coin \$j\$, etc.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate coin-level probabilities
coin_probs <- df_agg %>%
  group_by(coin) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at coin level
coin_summary <- coin_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(coin_summary)

```

The **mean coin-level probability** is about 0.504, with smaller overall variability compared to participants, as shown in Figure 3.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities by coin
fig3 <- ggplot(coin_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[4]) +
  labs(
    title = "Probability of Landing on the Same Side by Coin",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig3.png", plot = fig3, width = 8, height = 6, dpi = 300)
```

*Figure 3: Histogram of the probability of landing on the same side by coin.*

```{r}
#| echo: false
# Combine fig_participants (left) and fig_coins (right) side by side
fig_merged <- fig2 + fig3 + 
  plot_layout(ncol = 2) & 
  theme(plot.title = element_text(size = 12))

ggsave("fig_merged.png", plot = fig_merged, width = 10, height = 5, dpi = 300)

fig_merged

```

*Figure 4: Merged: Histogram of the probability of landing on the same side by participant and by coin.*

Outliers were identified for coins with probabilities exceeding two standard deviations from the mean.

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify coin outliers
coin_outliers <- coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(coin_outliers)
```

To further investigate, we analyzed person/coin combinations to explore whether specific participant-coin interactions exhibit unusual outcomes.

```{r,message=FALSE,warning=FALSE}
# Calculate probabilities for person/coin combinations
person_coin_probs <- df_agg %>%
  group_by(person, coin) %>%
  summarise(prob_same_side = mean(prob_same_side, na.rm = TRUE), .groups = "drop")

# Identify person/coin combination outliers
person_coin_outliers <- person_coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(person_coin_outliers)
```

**Effect of Starting Side**

Finally, we explore whether starting the coin heads-up vs. tails-up alters the likelihood of ending on the same side. We compare:

-   $p_{11}=P(Heads→Heads)$

-   $p_{00}=P(Tails→Tails)$

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Compare probabilities based on starting side
starting_side_probs <- df_agg %>%
  summarise(
    mean_prob_heads_to_heads = mean(prob_heads_to_heads, na.rm = TRUE),
    mean_prob_tails_to_tails = mean(prob_tails_to_tails, na.rm = TRUE),
    sd_prob_heads_to_heads = sd(prob_heads_to_heads, na.rm = TRUE),
    sd_prob_tails_to_tails = sd(prob_tails_to_tails, na.rm = TRUE)
  )

print(starting_side_probs)

```

The results indicate **both** heads-up and tails-up flips have a mean probability of about 0.508 of landing on the same side. A t-test reveals no significant difference between the two groups, implying that "heads-up" vs. "tails-up" starts do not systematically alter the bias once participant and coin factors are averaged out.


```{r,message=FALSE, warning=FALSE}
#| echo: false
# Prepare data for plotting
df_agg_long <- df_agg %>%
  select(prob_heads_to_heads, prob_tails_to_tails) %>%
  pivot_longer(
    cols = c(prob_heads_to_heads, prob_tails_to_tails),
    names_to = "starting_side",
    values_to = "probability"
  ) %>%
  mutate(
    starting_side = recode(starting_side,
                           prob_heads_to_heads = "Heads Up",
                           prob_tails_to_tails = "Tails Up")
  )

df_agg_long %>%
  group_by(starting_side) %>%
  summarise(mean_prob = mean(probability, na.rm = TRUE),
            sd_prob = sd(probability, na.rm = TRUE)) %>%
  print()

t.test(probability ~ starting_side, data = df_agg_long)
```

A violin plot (Figure 4) shows the distribution of these probabilities:

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Violin plot of probabilities by starting side
fig4 <- ggplot(df_agg_long, aes(x = starting_side, y = probability, fill = starting_side)) +
  geom_violin(trim = FALSE, alpha = 0.8, adjust = 0.75) +
  geom_boxplot(width = 0.1, fill = "white", color = "black", outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1) +
  scale_fill_manual(values = c(viridis(5)[1], viridis(5)[5])) +
  labs(
    title = "Probability of Landing on the Same Side by Starting Side",
    x = "Starting Side",
    y = "Probability"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

ggsave("fig4.png", plot = fig4, width = 8, height = 6, dpi = 300)
```

*Figure 5: Violin plot of the probability of landing on the same side by starting side.*

Both distributions are centered around 0.508, with comparable spread, suggesting **no notable systematic difference** between starting heads-up or tails-up. Some outliers in each group do appear, which may reflect unique participant behaviors or chance fluctuations.

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify outliers by starting side
starting_side_outliers <- df_agg_long %>%
  group_by(starting_side) %>%
  filter(probability > mean(probability) + 2 * sd(probability) |
           probability < mean(probability) - 2 * sd(probability))

print(starting_side_outliers)
```

#### **2. Analysis**

##### 2.1 Simple Logistic Regression Model

As a first step, we fit the simplest possible logistic model, treating **all flips** (aggregated in `df_agg_agg`) as independent Bernoulli trials with a single intercept term. Conceptually, this model estimates a single probability $p$ that a flip lands heads, irrespective of participant or coin.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Fit a simple logistic regression model
model_1 <- glm(cbind(heads_heads, N_start_heads_up - heads_heads) ~ 1, family = binomial, data = df_agg)
summary(model_1)
check_model(model_1)
```

##### 2.2 Random Intercepts for Participants Only

We first fit a GLMM that includes a random intercept for participants. This model captures variability in flipping outcomes across participants without considering coin-specific effects. The model is expressed as:
$$
\log \left( \frac{p_{ik}}{1 - p_{ik}} \right) = \beta_0 + \gamma_i
$$
where:
- $p_{ik}$: Probability of landing on the same side for the $k$-th flip by participant $i$.
- $\beta_0$: Fixed effect intercept, representing the overall log-odds across all participants.
- $\gamma_i$: Random effect for participant $i$, capturing variability in flipping styles.

```{r, message=FALSE, warning=FALSE}
#| echo: true
# Fit a mixed-effects logistic regression model with random intercepts for participants
model_2 <- glmer(cbind(total_same_side, total_flips - total_same_side) ~ 1 + 
                             (1 | person),
                           family = binomial, data = df_agg)
summary(model_2)
check_model(model_2)
```

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Extract model summary statistics
library(broom.mixed)
fixed_effects_participants <- tidy(model_2, effects = "fixed")
random_effects_participants <- tidy(model_2, effects = "ran_pars")

# Display fixed and random effects
print(fixed_effects_participants)
print(random_effects_participants)
```

##### 2.3 Random Intercepts for Participants and Coins Nested Within Participants
This extended model accounts for both participant-specific and coin-specific variability by including coins as random effects nested within participants. The model is expressed as:
$$
\log \left( \frac{p_{ijk}}{1 - p_{ijk}} \right) = \beta_0 + \gamma_i + \delta_{j(i)}
$$
where:
- \(\beta_0\): Fixed effect intercept, representing the overall log-odds of landing on the same side,
- \(\gamma_i\): Random effect for participant \(i\), capturing variability in flipping styles,
- \(\delta_{j(i)}\): Random effect for coin \(j\), nested within participant \(i\), capturing variability between coins flipped by the same participant.

```{r, message=FALSE, warning=FALSE}
#| echo: true
# Fit a mixed-effects logistic regression model with nested random intercepts
model_3 <- glmer(cbind(total_same_side, total_flips - total_same_side) ~ 1 + 
                      (1 | person/coin),
                    family = binomial, data = df_agg)
summary(model_3)
check_model(model_3)
```


```{r, message=FALSE, warning=FALSE}
#| echo: true

# Extract model summary statistics
fixed_effects_nested <- tidy(model_3, effects = "fixed")
random_effects_nested <- tidy(model_3, effects = "ran_pars")

# Display fixed and random effects
print(fixed_effects_nested)
print(random_effects_nested)
```

---
### **Comparison of Models**

To evaluate the importance of including hierarchical structures, we compare all models: the simple logistic regression model, the participants-only random effects model, and the participants-and-nested-coins random effects model. We use likelihood ratio tests, AIC, and BIC values to assess the models.

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Compare all three models using AIC, BIC, and log-likelihood
comparison <- data.frame(
  Model = c("Simple Logistic Regression", "Participants Only", "Participants and Nested Coins"),
  LogLikelihood = c(logLik(model_simple), logLik(glmm_participants), logLik(glmm_nested)),
  AIC = c(AIC(model_simple), AIC(glmm_participants), AIC(glmm_nested)),
  BIC = c(BIC(model_simple), BIC(glmm_participants), BIC(glmm_nested))
)

print(comparison)
```
## Results and Interpretation

### Simple Logistic Regression

The Simple Logistic Regression model has the highest log-likelihood (\(-868.8\)) and the lowest AIC (\(1739.6\)) and BIC (\(1742.9\)). This is because it assumes all flips are independent and identically distributed, which simplifies the model. However, this simplicity comes at the cost of ignoring the hierarchical structure of the data, such as variability between participants and coins.

### Participants-Only Model

Adding random intercepts for participants reduces the log-likelihood (\(-981.7\)) and increases both AIC (\(1967.4\)) and BIC (\(1974.1\)) compared to the simple model. This indicates that accounting for participant-specific variability improves the model fit but also adds complexity, as evidenced by the higher AIC and BIC values.  
This model highlights the importance of participant-level effects, but it assumes that all coins behave identically, which may not fully capture the variability in the data.

### Participants and Nested Coins Model

Adding nested coin effects further improves the model, with a log-likelihood of \(-977.1\), AIC of \(1960.2\), and BIC of \(1970.3\). The reductions in AIC and BIC compared to the Participants-Only model suggest that including coin-specific effects improves the fit while managing complexity better.

### Likelihood Ratio Tests

We use likelihood ratio tests (LRTs) to formally compare the models:

```{r}
# Perform likelihood ratio tests for nested models
anova(model_simple, glmm_participants, glmm_nested, test = "Chisq")
```
## Simple vs. Participants Only

The significant likelihood ratio test (\(p < 0.001\)) indicates that the participants-only model provides a much better fit to the data than the simple model. This improvement reflects the importance of capturing participant-specific variability.

## Participants Only vs. Participants and Nested Coins

The likelihood ratio test (\(p = 0.0025\)) supports the inclusion of nested coin effects, confirming that the additional complexity is justified.

## Key Takeaways

- **Simple Model**: Provides a good baseline but ignores variability due to participants and coins, which limits its explanatory power.
- **Participants-Only Model**: Captures participant-specific variability and significantly improves the fit over the simple model.
- **Participants and Nested Coins Model**: Further improves the model by accounting for coin-specific effects, although the improvement is smaller compared to the step from the simple model to the participants-only model. Participant-level variability remains the dominant factor.

While the participants-and-nested-coins model is the best-fitting model, the coin-level variability (\(\sigma_{\delta(j)}^2\)) is relatively small compared to participant-level variability (\(\sigma_{\gamma}^2\)). This suggests that flipping outcomes are primarily driven by participant-specific behavior rather than coin-specific characteristics.

## Conclusion

The participants-and-nested-coins model provides the most accurate representation of the data, as it accounts for both participant and coin-specific variability. However, the relatively small coin-level variance suggests that participants are the primary source of variability in flipping outcomes. These findings highlight the importance of modeling hierarchical structures to capture the complexity of the data.


## **Analysis of Learning Effects and Influence of Recent Flips**

Building on the previous analysis, we now investigate whether participants exhibit **learning effects** (i.e., improving flipping consistency over time) and whether **recent flips influence the outcome** of the current flip. These analyses allow us to better understand behavioral trends and potential dependencies in flipping outcomes.

---

### **Learning Effects**

#### **Objective**

To examine whether participants' probabilities of flipping a coin that lands on the same side improve over time, we analyze the relationship between the **flip sequence** (indexed by `flip_index`) and the probability of landing on the same side.

#### **Approach**

1. We include a sequential variable `flip_index` representing the order of flips for each participant.
2. We model learning effects using a generalized linear mixed model (GLMM) with `flip_index` as a fixed effect and random intercepts for participants and coins.

#### **Code and Results**

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Load the new dataset
df_agg_time <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/df_agg-time.csv")
# Ensure factors are properly set
df_agg_time <- df_agg_time %>%
  mutate(
    person = factor(person),
    coin = factor(coin),
    toss_start = factor(toss_start),
    toss_end = factor(toss_end)
  )

df_agg_time <- df_agg_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    lag_1 = lag(toss_end, 1),  # Outcome of the previous flip
    lag_2 = lag(toss_end, 2),  # Outcome of two flips ago
    lag_3 = lag(toss_end, 3)   # Outcome of three flips ago
  ) %>%
  ungroup()
# Check the first few rows
head(df_agg_time)

# Summarize the distribution of lagged variables
summary(df_agg_time[, c("lag_1", "lag_2", "lag_3")])

# Fit a logistic regression model to test the influence of recent flips
model_recent_flips <- glm(
  toss_end ~ lag_1 + lag_2 + lag_3, 
  family = binomial, 
  data = df_agg_time
)

# Summarize the model
summary(model_recent_flips)
```
```{r}
#| echo: true

# Create a summary table of probabilities based on lagged outcomes
lag_effects <- df_agg_time %>%
  group_by(lag_1, lag_2, lag_3) %>%
  summarise(
    prob_heads = mean(toss_end == "h", na.rm = TRUE),
    n = n()
  ) %>%
  filter(n > 10)  # Filter to include only combinations with sufficient observations

# Plot the probabilities
ggplot(lag_effects, aes(x = lag_1, y = prob_heads, fill = lag_2)) +
  geom_col(position = "dodge") +
  facet_wrap(~ lag_3, ncol = 2) +
  labs(
    title = "Effect of Recent Outcomes on Probability of Heads",
    x = "Lag 1 (Previous Toss Outcome)",
    y = "Probability of Heads",
    fill = "Lag 2 Outcome"
  ) +
  theme_minimal()
```


```{r}
#| echo: true

# Include interaction terms in the logistic regression model
model_interaction <- glm(
  toss_end ~ lag_1 * lag_2 * lag_3, 
  family = binomial, 
  data = df_agg_time
)

# Summarize the model with interaction terms
summary(model_interaction)
```

```{r}
#| echo: true

# Add a sequential flip index for learning effects
df_agg_time <- df_agg_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    flip_index = row_number()  # Sequential index for each flip within a sequence
  ) %>%
  ungroup()

# Visualize trends in probability of heads over sequential flips
learning_effects <- df_agg_time %>%
  group_by(flip_index) %>%
  summarise(
    prob_heads = mean(toss_end == "h", na.rm = TRUE),
    n = n()
  )

ggplot(learning_effects, aes(x = flip_index, y = prob_heads)) +
  geom_line(color = "blue") +
  geom_point(size = 2) +
  labs(
    title = "Learning Effects: Probability of Heads Over Sequential Flips",
    x = "Flip Index (Sequential Number)",
    y = "Probability of Heads"
  ) +
  theme_minimal()
```

```{r}
#| echo: true

# Fit a logistic regression model to investigate learning effects
model_learning <- glm(
  toss_end ~ flip_index, 
  family = binomial, 
  data = df_agg_time
)

# Summarize the learning effects model
summary(model_learning)
```

```{r}
#| echo: true

# Create interaction terms between lagged outcomes and the sequential flip index
df_agg_time <- df_agg_time %>%
  mutate(
    interaction_lag1_flip_index = as.numeric(lag_1 == "h") * flip_index,
    interaction_lag2_flip_index = as.numeric(lag_2 == "h") * flip_index,
    interaction_lag3_flip_index = as.numeric(lag_3 == "h") * flip_index
  )

# Fit a logistic regression model with interaction effects
model_interaction <- glm(
  toss_end == "h" ~ flip_index + lag_1 + lag_2 + lag_3 +
    interaction_lag1_flip_index + interaction_lag2_flip_index + interaction_lag3_flip_index,
  family = binomial,
  data = df_agg_time
)

# Summarize the interaction model
summary(model_interaction)
```

```{r}
#| echo: true

# Visualize interaction effects: Change in probability by flip index and recent flips
interaction_effects <- df_agg_time %>%
  mutate(
    lag_1_numeric = as.numeric(lag_1 == "h"),
    lag_2_numeric = as.numeric(lag_2 == "h"),
    lag_3_numeric = as.numeric(lag_3 == "h")
  ) %>%
  group_by(flip_index, lag_1_numeric) %>%
  summarise(
    prob_heads = mean(toss_end == "h", na.rm = TRUE),
    n = n()
  )

ggplot(interaction_effects, aes(x = flip_index, y = prob_heads, color = factor(lag_1_numeric))) +
  geom_line() +
  geom_point() +
  labs(
    title = "Interaction Effects: Probability of Heads by Flip Index and Lagged Outcome",
    x = "Flip Index (Sequential Number)",
    y = "Probability of Heads",
    color = "Lagged Outcome (Lag 1)"
  ) +
  theme_minimal()
```