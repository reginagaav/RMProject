---
title: "Regression Methods Project"
format: html
header-includes:
  - \usepackage{xcolor}  
  - \usepackage{amsmath} 
  - \usepackage{amssymb} 
  - \usepackage{bm}      
pdf-engine: xelatex      
---

#### **1. Introduction and Exploratory Data Analysis**

A recent paper (winner of the 2024 IgNobel Prize in Probability) analyzed over 350,000 coin flips to investigate the phenomenon that a coin starting heads-up tends to land heads-up with a probability slightly above 0.5, around 0.51, and similarly for tails-up. While the original paper adopted a Bayesian framework, our goal here is to employ frequentist regression methods to explore this possible bias and the factors that might influence it---such as participant-specific flipping techniques, coin characteristics, and the coin's starting orientation.

-   **State Objectives:**

    -   Clearly define the aims of your analysis.

-   **Outline:**

    -   Provide a roadmap of your report's structure.

**Data Description**

The dataset (in `data-agg.csv`) contains aggregated results from an experiment involving 48 participants flipping 211 different coins. Each row corresponds to the outcomes of flipping a *specific coin* by a *single participant* under two starting orientations: heads-up and tails-up. The columns are:

-   **heads_heads**: Number of flips that started heads-up and ended heads-up.

-   **tails_heads**: Number of flips that started tails-up and ended heads-up.

-   **N_start_heads_up**: Total flips that started heads-up.

-   **N_start_tails_up**: Total flips that started tails-up.

-   **person**: Participant identifier.

-   **coin**: Coin identifier.

We define for each row:

-   $ \text{heads_tails} = N_{\text{start_heads_up}} - \text{heads_heads}$
-   $ \text{tails_tails} = N_{\text{start_tails_up}} - \text{tails_heads}$
-   $ \text{prob_same_side} = \frac{\text{heads_heads} + \text{tails_tails}}{N_{\text{start_heads_up}} + N_{\text{start_tails_up}}}$

The overall interest lies in the extent to which $\text{prob_same_side}$ exceeds 0.50, and whether this bias depends on the participant, coin, or starting orientation. Our analysis begins with studying the patterns in the data to inform modeling.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Load necessary libraries
library(tidyverse)
library(glue)
library(viridis)

# Read the data
df <- read_csv("/Users/graceaverell/Desktop/EPFL/regression methods/coin data/analyses/data-agg.csv") %>%
  mutate(
    person = factor(person),
    coin = factor(coin)
  )

```

**Overall Probability of Landing on the Same Side**

To assess the overall bias, we first compute how often the coin ends on the same side it started.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate flips where the coin landed on the opposite side
df <- df %>%
  mutate(
    heads_tails = N_start_heads_up - heads_heads,
    tails_tails = N_start_tails_up - tails_heads
  )

# Calculate total flips and probabilities
df <- df %>%
  mutate(
    total_flips = N_start_heads_up + N_start_tails_up,
    total_same_side = heads_heads + tails_tails,
    prob_same_side = total_same_side / total_flips,
    prob_heads_to_heads = heads_heads / N_start_heads_up,
    prob_tails_to_tails = tails_tails / N_start_tails_up
  )

# Summary statistics for probability of landing on the same side}
summary_stats <- df %>%
  summarise(
    mean_prob_same_side = mean(prob_same_side, na.rm = TRUE),
    median_prob_same_side = median(prob_same_side, na.rm = TRUE),
    sd_prob_same_side = sd(prob_same_side, na.rm = TRUE)
  )

print(summary_stats)
```

```{r, message=FALSE, warning=FALSE}
#| echo: false
t.test(df$prob_same_side, mu = 0.5, alternative = "two.sided")
```

From these results, we find a **mean probability** of about 0.508, slightly exceeding 0.5. A one-sample t-test against 0.5 indicates a statistically significant difference $(p< 0.05)$. Although the magnitude of this effect is small, it suggests a bias toward coins landing on the same side they started.

We visualize the distribution of these probabilities in Figure 1.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side
ggplot(df, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[2]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

```

*Figure 1: Histogram of the probability of landing on the same side across all coins and participants.*

Most probabilities cluster around 0.5, but the distribution leans slightly to the right, reflecting the small bias observed. A few outliers exceed 0.6, which we will explore further.

**Participant-Level Analysis**

Next, we examine how this probability varies by participant. Differences in flipping technique or style could drive variation at the individual level.

We sum heads-up and tails-up flips by participant to obtain

$ p_i = \frac{(\text{heads_heads})_i + (\text{tails_tails})_i}{(\text{total_flips})_i}$

where $(\text{heads_heads})_i$ is the total number of heads outcomes from heads-up starts for participant $i$, etc.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate participant-level probabilities
participant_probs <- df %>%
  group_by(person) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at participant level
participant_summary <- participant_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(participant_summary)

```

The **mean participant-level probability** is around 0.510, slightly higher than the overall mean. This minor increase above the grand mean suggests participants differ in their flipping styles, possibly through differences in technique or consistency. This is illustrated in Figure 2.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side by participant
ggplot(participant_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[3]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side by Participant",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()
```

*Figure 2: Histogram of Probability of Landing on the Same Side by Participant*

Although many participants cluster near 0.5, there are some notable outliers, reinforcing the notion that **participant-specific effects** could be important in modeling. We identify outliers by checking which participants' probabilities lie beyond two standard deviations from the mean.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Identify participants with extreme probabilities
participant_outliers <- participant_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(participant_outliers)

```

**Coin-Level Analysis**

We then group flips by each *coin* to see whether some coins inherently land on the same side more frequently. Analogously, we compute

$q_j = \frac{(\text{heads_heads})_j + (\text{tails_tails})_j}{(\text{total_flips})_j}$

where $(\text{heads_heads})_j$ denotes the total number of heads outcomes from heads-up starts for coin \$j\$, etc.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate coin-level probabilities
coin_probs <- df %>%
  group_by(coin) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at coin level
coin_summary <- coin_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(coin_summary)

```

The **mean coin-level probability** is about 0.504, with smaller overall variability compared to participants, as shown in Figure 3.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities by coin
ggplot(coin_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[4]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side by Coin",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()


```

*Figure 3: Histogram of the probability of landing on the same side by coin.*

Coin-level probabilities remain tightly grouped around 0.5. This finding indicates that, **on average**, coin characteristics may not strongly affect the outcome, at least not to the same extent as participant-specific effects. Outliers were identified for coins with probabilities exceeding two standard deviations from the mean.

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify coin outliers
coin_outliers <- coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(coin_outliers)
```

To further investigate, we analyzed person/coin combinations to explore whether specific participant-coin interactions exhibit unusual outcomes.

```{r,message=FALSE,warning=FALSE}
# Calculate probabilities for person/coin combinations
person_coin_probs <- df %>%
  group_by(person, coin) %>%
  summarise(prob_same_side = mean(prob_same_side, na.rm = TRUE), .groups = "drop")

# Identify person/coin combination outliers
person_coin_outliers <- person_coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(person_coin_outliers)
```

TianqiPeng and JanYang were identified as outlier participants.

\*\*maybe say something else??? lol im tired and not so sure\*\*

**Effect of Starting Side**

Finally, we explore whether starting the coin heads-up vs. tails-up alters the likelihood of ending on the same side. We compare:

-   $p_{11}=P(Heads→Heads)$

-   $p_{00}=P(Tails→Tails)$

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Compare probabilities based on starting side
starting_side_probs <- df %>%
  summarise(
    mean_prob_heads_to_heads = mean(prob_heads_to_heads, na.rm = TRUE),
    mean_prob_tails_to_tails = mean(prob_tails_to_tails, na.rm = TRUE),
    sd_prob_heads_to_heads = sd(prob_heads_to_heads, na.rm = TRUE),
    sd_prob_tails_to_tails = sd(prob_tails_to_tails, na.rm = TRUE)
  )

print(starting_side_probs)

```

The results indicate **both** heads-up and tails-up flips have a mean probability of about 0.508 of landing on the same side. A t-test reveals no significant difference between the two groups, implying that "heads-up" vs. "tails-up" starts do not systematically alter the bias once participant and coin factors are averaged out.

ive been thinking of how davison said hypothesis tests are overused is this one of those cases? or is it a reasonable test? i think so but im also overthinking

```{r,message=FALSE, warning=FALSE}
#| echo: false
# Prepare data for plotting
df_long <- df %>%
  select(prob_heads_to_heads, prob_tails_to_tails) %>%
  pivot_longer(
    cols = c(prob_heads_to_heads, prob_tails_to_tails),
    names_to = "starting_side",
    values_to = "probability"
  ) %>%
  mutate(
    starting_side = recode(starting_side,
                           prob_heads_to_heads = "Heads Up",
                           prob_tails_to_tails = "Tails Up")
  )

df_long %>%
  group_by(starting_side) %>%
  summarise(mean_prob = mean(probability, na.rm = TRUE),
            sd_prob = sd(probability, na.rm = TRUE)) %>%
  print()

t.test(probability ~ starting_side, data = df_long)
```

A violin plot (Figure 4) shows the distribution of these probabilities:

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Violin plot of probabilities by starting side
ggplot(df_long, aes(x = starting_side, y = probability, fill = starting_side)) +
  geom_violin(trim = FALSE, alpha = 0.8, adjust = 0.75) +
  geom_boxplot(width = 0.1, fill = "white", color = "black", outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1) +
  scale_fill_manual(values = c(viridis(5)[1], viridis(5)[5])) +
  labs(
    title = "Probability of Landing on the Same Side by Starting Side",
    x = "Starting Side",
    y = "Probability"
  ) +
  theme_minimal() +
  theme(legend.position = "none")


```

*Figure 4: Violin plot of the probability of landing on the same side by starting side.*

Both distributions are centered around 0.508, with comparable spread, suggesting **no notable systematic difference** between starting heads-up or tails-up. Some outliers in each group do appear, which may reflect unique participant behaviors or chance fluctuations.

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify outliers by starting side
starting_side_outliers <- df_long %>%
  group_by(starting_side) %>%
  filter(probability > mean(probability) + 2 * sd(probability) |
           probability < mean(probability) - 2 * sd(probability))

print(starting_side_outliers)
```

**Summary of EDA Findings**

-   **Slight Overall Bias**: The mean probability of landing on the same side is 0.508, slightly above 0.5, indicating a modest but statistically significant bias.

-   **Participant Variability**: A higher mean (0.510) and greater spread among participants highlight the importance of participant-specific effects. The outliers indicate certain participants might be flipping coins in a non-random manner.

-   **Minimal Coin Influence**: Coin-level probabilities are tightly clustered around 0.5, suggesting coin characteristics may not play a major role ompared to participant influences ---at least in this aggregated dataset.

-   **Starting Side**: Heads-up or tails-up leads to virtually the same probability (0.508), indicating little difference in bias by orientation.

These observations will guide the model-building phase. In particular, **participant effects** seem important, whereas coin effects appear weaker. Although starting side does not show a strong effect overall, we may still retain it in our models to capture any subtle differences.

#### **3. Analysis**

Building upon the insights from our EDA, we proceed to model the probability of a coin landing on the same side using generalized linear models (GLMs). Given the binary nature of the outcome (landing on the same side or not), logistic regression is an appropriate choice. We begin with a simple model and later incorporate hierarchical structures to account for variability.

##### Simple Logistic Regression Model

As a first step, we fit the simplest possible logistic model, treating **all flips** (aggregated in `df`) as independent Bernoulli trials with a single intercept term. Conceptually, this model estimates a single probability \$p\$ that a flip lands heads, irrespective of participant or coin. Though extremely simplistic, it provides a baseline for more complex models.

Let $Y\_{ij}$ denote the number of same-side outcomes for the $i$-th participant-coin pair under starting orientation $j$, and let $m_{ij}$ represent the total flips under these conditions. A simple logistic regression assumes: $\text{logit}\bigl(P(Y_{ij} = 1)\bigr) = \beta_0$ where $\beta_0 \in \mathbb{R}$ is the log-odds of landing on the same side, irrespective of participant, coin, or starting orientation. The likelihood for $\beta_0$ is: $ L(\beta_0) =\prod{i,j} \binom{m_{ij}}{Y_{ij}} \pi^{Y_{ij}} (1 - \pi)^{m\_{ij} - Y_{ij}}$ where $\pi = \frac{\exp(\beta_0)}{1 + \exp(\beta_0)}$. The maximum likelihood estimate $\hat{\beta}_0\$ is obtained by solving 
$ \max_{\beta_0} \sum_{i,j} Y_{ij} \log(\pi) + (m_{ij} - Y_{ij}) \log(1 - \pi)$


```{r, message=FALSE, warning=FALSE}
#| echo: false
# Fit a simple logistic regression model
model_simple <- glm(cbind(heads_heads, N_start_heads_up - heads_heads) ~ 1, family = binomial, data = df)
summary(model_simple)
```


```{r, message=FALSE, warning=FALSE}
#| echo: false

```
