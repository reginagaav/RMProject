---
title: "Regression Methods Project"
format: html
header-includes:
  - \usepackage{xcolor}  
  - \usepackage{amsmath} 
  - \usepackage{amssymb} 
  - \usepackage{bm}      
pdf_agg-engine: xelatex      
---

#### **1. Introduction and Exploratory Data Analysis**

Our analysis begins with studying the patterns in the data to inform modeling. 

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Load necessary libraries
library(tidyverse)
library(glue)
library(viridis)
library(ggplot2)
library(dplyr)
library(performance)

# Read the aggregated dataset
df_agg <- read_csv("/Users/graceaverell/Desktop/EPFL/regression methods/coin data/analyses/data-agg.csv") %>%
  mutate(
    person = factor(person),
    coin = factor(coin)
  )

#df_agg <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/data-agg.csv") %>%
#  mutate(
#    person = factor(person),
#    coin = factor(coin)
#  )

# Read the time-resolved dataset
df_agg_time <- read_csv("/Users/graceaverell/Desktop/EPFL/regression methods/coin data/analyses/df-time.csv") %>%
  mutate(
    person     = factor(person),
    coin       = factor(coin),
    toss_start = factor(toss_start),
    toss_end   = factor(toss_end)
  ) %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    lag_1 = lag(toss_end, 1),
    lag_2 = lag(toss_end, 2),
    lag_3 = lag(toss_end, 3)
  ) %>%
  ungroup()

#df_agg_time <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/df_agg-time.csv") %>%
#  mutate(
#    person     = factor(person),
#    coin       = factor(coin),
#    toss_start = factor(toss_start),
#    toss_end   = factor(toss_end)
#  ) %>%
#  arrange(person, sequence_id, toss_number) %>%
#  group_by(person, sequence_id) %>%
#  mutate(
#    lag_1 = lag(toss_end, 1),
#    lag_2 = lag(toss_end, 2),
#    lag_3 = lag(toss_end, 3)
#  ) %>%
#  ungroup()

# Check the first few rows
head(df_agg_time)

```

##### **1.1. EDA for Aggregated Data (df_agg)**

**Overall Probability of Landing on the Same Side**

To assess the overall bias, we first compute how often the coin ends on the same side it started.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate flips where the coin landed on the opposite side
df_agg <- df_agg %>%
  mutate(
    heads_tails = N_start_heads_up - heads_heads,
    tails_tails = N_start_tails_up - tails_heads
  )

# Calculate total flips and probabilities
df_agg <- df_agg %>%
  mutate(
    total_flips = N_start_heads_up + N_start_tails_up,
    total_same_side = heads_heads + tails_tails,
    prob_same_side = total_same_side / total_flips,
    prob_heads_to_heads = heads_heads / N_start_heads_up,
    prob_tails_to_tails = tails_tails / N_start_tails_up
  )

# Summary statistics for probability of landing on the same side}
summary_stats <- df_agg %>%
  summarise(
    mean_prob_same_side = mean(prob_same_side, na.rm = TRUE),
    median_prob_same_side = median(prob_same_side, na.rm = TRUE),
    sd_prob_same_side = sd(prob_same_side, na.rm = TRUE)
  )

print(summary_stats)
```

```{r, message=FALSE, warning=FALSE}
#| echo: false
t.test(df_agg$prob_same_side, mu = 0.5, alternative = "two.sided")
```

From these results, we find a **mean probability** of about 0.508, slightly exceeding 0.5. A one-sample t-test against 0.5 indicates a statistically significant difference ($p < 0.05$). We visualize the distribution of these probabilities in Figure 1.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side

fig1 <- ggplot(df_agg, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[2]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig1.png", plot = fig1, width = 8, height = 6, dpi = 300)
```

*Figure 1: Histogram of the probability of landing on the same side across all coins and participants.*


**Participant-Level Analysis**

Next, we examine how this probability varies by participant. 

We sum heads-up and tails-up flips by participant to obtain

$p_i = \frac{(\text{heads_heads})_i + (\text{tails_tails})_i}{(\text{total_flips})_i}$

where $(\text{heads_heads})_i$ is the total number of heads outcomes from heads-up starts for participant $i$, etc.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate participant-level probabilities
participant_probs <- df_agg %>%
  group_by(person) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at participant level
participant_summary <- participant_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(participant_summary)

```

The **mean participant-level probability** is around 0.510, slightly higher than the overall mean. This is illustrated in Figure 2.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities of landing on the same side by participant
fig2 <- ggplot(participant_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[3]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side by Participant",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig2.png", plot = fig2, width = 8, height = 6, dpi = 300)
```

*Figure 2: Histogram of Probability of Landing on the Same Side by Participant*

We identify outliers by checking which participants' probabilities lie beyond two standard deviations from the mean.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Identify participants with extreme probabilities
participant_outliers <- participant_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(participant_outliers)

```

**Coin-Level Analysis**

We then group flips by each *coin* to see whether some coins inherently land on the same side more frequently. Analogously, we compute

$q_j = \frac{(\text{heads_heads})_j + (\text{tails_tails})_j}{(\text{total_flips})_j}$

where $(\text{heads_heads})_j$ denotes the total number of heads outcomes from heads-up starts for coin \$j\$, etc.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Calculate coin-level probabilities
coin_probs <- df_agg %>%
  group_by(coin) %>%
  summarise(
    total_heads_heads = sum(heads_heads),
    total_tails_tails = sum(tails_tails),
    total_heads_up = sum(N_start_heads_up),
    total_tails_up = sum(N_start_tails_up),
    total_same_side = total_heads_heads + total_tails_tails,
    total_flips = total_heads_up + total_tails_up,
    prob_same_side = total_same_side / total_flips
  )

# Summary statistics at coin level
coin_summary <- coin_probs %>%
  summarise(
    mean_prob = mean(prob_same_side),
    median_prob = median(prob_same_side),
    sd_prob = sd(prob_same_side)
  )

print(coin_summary)

```

The **mean coin-level probability** is about 0.504, with smaller overall variability compared to participants, as shown in Figure 3.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Histogram of probabilities by coin
fig3 <- ggplot(coin_probs, aes(x = prob_same_side)) +
  geom_histogram(binwidth = 0.001, color = "black", fill = viridis(5)[4]) +
  labs(
    title = "Histogram of Probability of Landing on the Same Side by Coin",
    x = "Probability",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("fig3.png", plot = fig3, width = 8, height = 6, dpi = 300)
```

*Figure 3: Histogram of the probability of landing on the same side by coin.*

Outliers were identified for coins with probabilities exceeding two standard deviations from the mean.

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify coin outliers
coin_outliers <- coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(coin_outliers)
```

To further investigate, we analyzed person/coin combinations to explore whether specific participant-coin interactions exhibit unusual outcomes.

```{r,message=FALSE,warning=FALSE}
# Calculate probabilities for person/coin combinations
person_coin_probs <- df_agg %>%
  group_by(person, coin) %>%
  summarise(prob_same_side = mean(prob_same_side, na.rm = TRUE), .groups = "drop")

# Identify person/coin combination outliers
person_coin_outliers <- person_coin_probs %>%
  filter(prob_same_side > mean(prob_same_side) + 2 * sd(prob_same_side) |
           prob_same_side < mean(prob_same_side) - 2 * sd(prob_same_side))

print(person_coin_outliers)
```

**Effect of Starting Side**

Finally, we explore whether starting the coin heads-up vs. tails-up alters the likelihood of ending on the same side. We compare:

-   $p_{11}=P(Heads→Heads)$

-   $p_{00}=P(Tails→Tails)$

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Compare probabilities based on starting side
starting_side_probs <- df_agg %>%
  summarise(
    mean_prob_heads_to_heads = mean(prob_heads_to_heads, na.rm = TRUE),
    mean_prob_tails_to_tails = mean(prob_tails_to_tails, na.rm = TRUE),
    sd_prob_heads_to_heads = sd(prob_heads_to_heads, na.rm = TRUE),
    sd_prob_tails_to_tails = sd(prob_tails_to_tails, na.rm = TRUE)
  )

print(starting_side_probs)

```

The results indicate **both** heads-up and tails-up flips have a mean probability of about 0.508 of landing on the same side. A t-test reveals no significant difference between the two groups, implying that "heads-up" vs. "tails-up" starts do not systematically alter the bias once participant and coin factors are averaged out.


```{r,message=FALSE, warning=FALSE}
#| echo: false
# Prepare data for plotting
df_agg_long <- df_agg %>%
  select(prob_heads_to_heads, prob_tails_to_tails) %>%
  pivot_longer(
    cols = c(prob_heads_to_heads, prob_tails_to_tails),
    names_to = "starting_side",
    values_to = "probability"
  ) %>%
  mutate(
    starting_side = recode(starting_side,
                           prob_heads_to_heads = "Heads Up",
                           prob_tails_to_tails = "Tails Up")
  )

df_agg_long %>%
  group_by(starting_side) %>%
  summarise(mean_prob = mean(probability, na.rm = TRUE),
            sd_prob = sd(probability, na.rm = TRUE)) %>%
  print()

t.test(probability ~ starting_side, data = df_agg_long)
```

A violin plot (Figure 4) shows the distribution of these probabilities:

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Violin plot of probabilities by starting side
fig4 <- ggplot(df_agg_long, aes(x = starting_side, y = probability, fill = starting_side)) +
  geom_violin(trim = FALSE, alpha = 0.8, adjust = 0.75) +
  geom_boxplot(width = 0.1, fill = "white", color = "black", outlier.shape = NA) +
  geom_jitter(width = 0.15, alpha = 0.5, color = "black", size = 1) +
  scale_fill_manual(values = c(viridis(5)[1], viridis(5)[5])) +
  labs(
    title = "Probability of Landing on the Same Side by Starting Side",
    x = "Starting Side",
    y = "Probability"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

ggsave("fig4.png", plot = fig4, width = 8, height = 6, dpi = 300)
```

*Figure 4: Violin plot of the probability of landing on the same side by starting side.*

Both distributions are centered around 0.508, with comparable spread, suggesting **no notable systematic difference** between starting heads-up or tails-up. Some outliers in each group do appear, which may reflect unique participant behaviors or chance fluctuations.

```{r,message=FALSE,warning=FALSE}
#| echo: false
# Identify outliers by starting side
starting_side_outliers <- df_agg_long %>%
  group_by(starting_side) %>%
  filter(probability > mean(probability) + 2 * sd(probability) |
           probability < mean(probability) - 2 * sd(probability))

print(starting_side_outliers)
```

##### **1.2. EDA for Time-Resolved Data (df_agg_time)**

Unlike df_agg, which is aggregated by participant–coin pairs, the dataset df_agg_time details each individual flip (350,757 rows total). This format allows us to explore:

* Learning or Fatigue Effects: Does the probability of a coin landing on the same side change over the sequence of flips?
* Lagged Outcomes: Variables lag_1, lag_2, lag_3 record how many flips ago were heads or tails, enabling us to check for short-term dependencies.
* Timing of Flips by Participant: Some participants might show changes in technique over many flips.

```{r}
# Streak or “Hot-Hand” Analysis

# 1) Ensure we have a logical variable for landing on the same side
df_agg_time <- df_agg_time %>%
  mutate(same_side = (toss_start == toss_end))

# 2) Define a function to compute streak lengths of `TRUE` in a logical vector
compute_streaks <- function(x) {
  streaks <- c()    # store the lengths of consecutive TRUE streaks
  count <- 0        # current streak length
  
  for (val in x) {
    if (val) {
      # increment if the current flip is TRUE
      count <- count + 1
    } else {
      # if we hit a FALSE, record the current streak (if any) and reset
      if (count > 0) {
        streaks <- c(streaks, count)
      }
      count <- 0
    }
  }
  
  # if the vector ends on a TRUE streak, record that as well
  if (count > 0) {
    streaks <- c(streaks, count)
  }
  
  return(streaks)
}

# 3) Apply the function for each (person, sequence_id)
streaks_df <- df_agg_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  summarise(
    # compute vector of same_side
    streaks_list = list(compute_streaks(same_side))
  ) %>%
  ungroup()

# 4) 'streaks_list' is a list-column containing numeric vectors of streak lengths
#    Flatten it out for plotting or summary
library(tidyr)

streaks_unnested <- streaks_df %>%
  unnest(cols = streaks_list) %>%
  rename(streak_length = streaks_list)

# 5) Summarize or visualize
summary(streaks_unnested$streak_length)

# simple histogram of streak lengths
library(ggplot2)

ggplot(streaks_unnested, aes(x = streak_length)) +
  geom_histogram(binwidth = 1, color = "black", fill = "steelblue") +
  labs(
    title = "Distribution of Streak Lengths (Same Side)",
    x = "Streak Length",
    y = "Count"
  ) +
  theme_minimal()


# Example: simulate the same number of flips with p=0.508
# and compare streak distributions
n_flips <- nrow(df_agg_time) # total flips
set.seed(123)
sim_flips <- rbinom(n_flips, size = 1, prob = 0.508) # 1 = same_side
sim_df <- data.frame(same_side = sim_flips == 1)

# compute streaks in the simulated data (single sequence for simplicity)
sim_streaks <- compute_streaks(sim_df$same_side)

# compare histograms or do a more formal test (e.g., chi-square)



```

```{r}
# Transition Probabilities (Markov-Type Check)

# 1) We need lag_1 or define it on the fly
# analogously can be done for lag2 and 3
df_agg_time <- df_agg_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(lag_1 = lag(toss_end, 1)) %>%
  ungroup()

# 2) Compute transition probability: P(next flip = h | previous flip = h)
transition_probs <- df_agg_time %>%
  filter(!is.na(lag_1)) %>%
  group_by(lag_1) %>%
  summarise(
    count_curr_head = sum(toss_end == "h"),
    count_total     = n(),
    prob_curr_head  = mean(toss_end == "h")
  )

print(transition_probs)

library(dplyr)
library(ggplot2)

transition_plot_df <- df_agg_time %>%
  filter(!is.na(lag_1)) %>%
  mutate(
    prev_flip = factor(lag_1, levels = c("h", "t")),
    curr_flip = factor(toss_end, levels = c("h", "t"))
  ) %>%
  group_by(prev_flip, curr_flip) %>%
  tally() %>%
  group_by(prev_flip) %>%
  mutate(prob = n / sum(n)) %>%
  ungroup()

ggplot(transition_plot_df, aes(x = prev_flip, y = prob, fill = curr_flip)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Transition Probabilities for (prev_flip -> curr_flip)",
    x = "Previous Flip Outcome",
    y = "Probability"
  ) +
  scale_fill_viridis_d(name = "Current Flip") +
  theme_minimal()

# Bars show the conditional probability of ending heads or tails given the previous outcome. If memoryless, bars for heads/tails should be roughly the same in each facet.

```

```{r}
# Learning or Fatigue Curves
df_sequence_summary <- df_agg_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    # For instance, focusing on heads in toss_end
    cumulative_heads = cumsum(toss_end == "h"),
    prop_heads_so_far = cumulative_heads / toss_number
  ) %>%
  ungroup()

ggplot(df_sequence_summary, aes(x = toss_number, y = prop_heads_so_far, group = sequence_id)) +
  geom_line(alpha = 0.4) +
  facet_wrap(~ person, scales = "free_y") +
  labs(
    title = "Learning or Fatigue Curves by Participant and Sequence",
    x = "Toss Number",
    y = "Proportion of Heads So Far"
  ) +
  theme_minimal()


```


#### **2. Analysis**

Building upon the insights from our EDA, we proceed to model the probability of a coin landing on the same side using generalized linear models (GLMs). Given the binary nature of the outcome (landing on the same side or not), logistic regression is an appropriate choice. We begin with a simple model and later incorporate hierarchical structures to account for variability.

##### 2.1 Simple Logistic Regression Model

As a first step, we fit the simplest possible logistic model, treating **all flips** (aggregated in `df_agg_agg`) as independent Bernoulli trials with a single intercept term. Conceptually, this model estimates a single probability $p$ that a flip lands heads, irrespective of participant or coin.

```{r, message=FALSE, warning=FALSE}
#| echo: false
# Fit a simple logistic regression model
model_simple <- glm(cbind(heads_heads, N_start_heads_up - heads_heads) ~ 1, family = binomial, data = df_agg)
summary(model_simple)
check_model(model_simple)
```

**Model Output**

Fitting the model yields an estimated log-odds of $\hat{\beta}_0 \approx 0.032$, corresponding to a probability
\[
\hat{p} = \frac{\exp(\hat{\beta}_0)}{1 + \exp(\hat{\beta}_0)} \approx 0.508.
\]
The intercept is statistically significant ($ p < 0.001 $) and the confidence interval for $\hat{p}$ excludes 0.50, aligning with the exploratory analysis and confirming a slight but significant bias in favor of landing on the same side.


**Model Fit**

-   Null Deviance: 284.28
-   Residual Deviance: 284.28
-   AIC: 1739.6

The residual deviance equals the null deviance since no predictors were included, and the AIC provides a benchmark for model comparisons.

While this model captures the overall probability, it assumes that all flips are independent and identically distributed Bernoulli trials, ignoring potential variability due to participant effects, coin characteristics, or starting orientation. Further modeling will incorporate these factors to capture hierarchical structures and dependencies.

## **2.2 Incorporating Hierarchical Structures**

The simple logistic regression model provided a useful baseline, estimating an overall bias ($\hat{p} \approx 0.508$) toward coins landing on the same side. However, it assumes all flips are independent and identically distributed, ignoring:
- Participant-specific flipping styles.
- Coin-specific physical characteristics.

To address these issues, we fit hierarchical models using **generalized linear mixed models (GLMMs)**. These models account for variability at different levels, starting with participants and then considering coins nested within participants.

### **Model 1: Random Intercepts for Participants Only**

#### **Model Specification**

We first fit a GLMM that includes a random intercept for participants. This model captures variability in flipping outcomes across participants without considering coin-specific effects. The model is expressed as:
$$
\log \left( \frac{p_{ik}}{1 - p_{ik}} \right) = \beta_0 + \gamma_i
$$
where:
- $p_{ik}$: Probability of landing on the same side for the $k$-th flip by participant $i$.
- $\beta_0$: Fixed effect intercept, representing the overall log-odds across all participants.
- $\gamma_i$: Random effect for participant $i$, capturing variability in flipping styles.

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Load necessary library
library(lme4)

# Fit a mixed-effects logistic regression model with random intercepts for participants
glmm_participants <- glmer(cbind(total_same_side, total_flips - total_same_side) ~ 1 + 
                             (1 | person),
                           family = binomial, data = df_agg)

# Summarize the model
summary(glmm_participants)
```

### **Model Results**

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Extract model summary statistics
library(broom.mixed)
fixed_effects_participants <- tidy(glmm_participants, effects = "fixed")
random_effects_participants <- tidy(glmm_participants, effects = "ran_pars")

# Display fixed and random effects
print(fixed_effects_participants)
print(random_effects_participants)
```
### **Results and Interpretation**

#### **Fixed Effect (\(\beta_0\)):**
The intercept (\(\beta_0 = 0.039884\)) represents the average log-odds of landing on the same side across all participants. Transforming this into a probability:
$$
\hat{p} = \frac{\exp(0.039884)}{1 + \exp(0.039884)} \approx 0.51
$$
This suggests a small but statistically significant bias (\(p < 0.001\)) toward coins landing on the same side (\(51\%\)).

#### **Random Effect Variance (\(\sigma_{\gamma}^2\)):**
The participant-specific random intercepts have a variance of \(\sigma_{\gamma}^2 = 0.003917\), corresponding to a standard deviation of \(\sigma_\gamma = 0.06258\). This indicates that while flipping styles vary between participants, the variability is relatively small compared to the overall scale of the fixed effect.

#### **Model Fit:**
The AIC of 1967.4 and log-likelihood of -981.7 provide benchmarks for comparison with more complex models.

#### **Limitations and Motivation for Next Model**
While this model captures participant-level variability, it assumes that all coins behave identically, which is likely unrealistic given differences in physical properties (e.g., weight, size, and material). Moreover, each coin is specific to a participant, introducing a nested structure in the data. Ignoring this structure may lead to an incomplete understanding of variability, as both participant-level effects (\(\sigma_{\gamma}^2\)) and coin-level effects (\(\sigma_{\delta(j)}^2\)) could contribute to the outcomes.

To better capture this nested structure and disentangle participant and coin-specific variability, we extend the model to include random intercepts for both participants and coins.

---

### **Model 2: Random Intercepts for Participants and Coins Nested Within Participants**

#### **Model Specification**
This extended model accounts for both participant-specific and coin-specific variability by including coins as random effects nested within participants. The model is expressed as:
$$
\log \left( \frac{p_{ijk}}{1 - p_{ijk}} \right) = \beta_0 + \gamma_i + \delta_{j(i)}
$$
where:
- \(\beta_0\): Fixed effect intercept, representing the overall log-odds of landing on the same side,
- \(\gamma_i\): Random effect for participant \(i\), capturing variability in flipping styles,
- \(\delta_{j(i)}\): Random effect for coin \(j\), nested within participant \(i\), capturing variability between coins flipped by the same participant.

This extension allows us to quantify the contribution of coin-specific variability relative to participant-specific variability, addressing the limitations of the first model and providing a more accurate representation of the data structure.

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Fit a mixed-effects logistic regression model with nested random intercepts
glmm_nested <- glmer(cbind(total_same_side, total_flips - total_same_side) ~ 1 + 
                      (1 | person/coin),
                    family = binomial, data = df_agg)

# Summarize the model
summary(glmm_nested)
```

### **Model Results**

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Extract model summary statistics
fixed_effects_nested <- tidy(glmm_nested, effects = "fixed")
random_effects_nested <- tidy(glmm_nested, effects = "ran_pars")

# Display fixed and random effects
print(fixed_effects_nested)
print(random_effects_nested)
```
### **Results and Interpretation**
//maybe this is a bit repetitive//

The results are as follows:

- **Fixed Effect (\(\beta_0\)):**
    - The fixed intercept (\(\beta_0 = 0.038513\)) represents the average **log-odds** of landing on the same side across all participants and coins. Converting this to a probability:
      
      $\hat{p} = \frac{\exp(0.038513)}{1 + \exp(0.038513)} \approx 0.51 $
      This suggests a slight but statistically significant bias (\(p < 0.001\)) toward coins landing on the same side (\(51\%\)).

- **Random Effect Variances:**
    - **Participant Variability (\(\sigma_{\gamma}^2\)):**
        - The participant-specific random intercepts have a variance of \(\sigma_{\gamma}^2 = 0.003631\), corresponding to a standard deviation of \(\sigma_\gamma = 0.06026\). This indicates that differences in flipping styles between participants are the primary source of variability.
    - **Coin Variability Nested Within Participants (\(\sigma_{\delta(j)}^2\)):**
        - The variance for coins nested within participants is \(\sigma_{\delta(j)}^2 = 0.000844\), with a standard deviation of \(\sigma_{\delta(j)} = 0.02905\). This reflects some additional variability due to individual coins, though it is smaller compared to participant-level variability.

- **Model Fit:**
    - The AIC of 1960.2 and log-likelihood of -977.1 indicate a slight improvement in model fit compared to Model 1 (AIC = 1967.4, log-likelihood = -981.7). This suggests that including coin-specific variability improves the model's explanatory power, though the improvement is modest.

#### **Key Insights:**
- **Dominance of Participant Effects:** The variability attributable to participants (\(\sigma_{\gamma}^2\)) is substantially larger than the variability attributable to coins (\(\sigma_{\delta(j)}^2\)), suggesting that flipping outcomes are primarily influenced by participant-specific behavior rather than coin-specific characteristics.
- **Hierarchical Structure:** By accounting for coins nested within participants, this model provides a more accurate representation of the data's structure, successfully partitioning variability at both levels.

This model enhances the understanding of flipping outcomes by capturing both participant and coin-level effects, confirming that participant-level variability is the dominant factor.

---
### **Comparison of Models**

To evaluate the importance of including hierarchical structures, we compare all models: the simple logistic regression model, the participants-only random effects model, and the participants-and-nested-coins random effects model. We use likelihood ratio tests, AIC, and BIC values to assess the models.

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Compare all three models using AIC, BIC, and log-likelihood
comparison <- data.frame(
  Model = c("Simple Logistic Regression", "Participants Only", "Participants and Nested Coins"),
  LogLikelihood = c(logLik(model_simple), logLik(glmm_participants), logLik(glmm_nested)),
  AIC = c(AIC(model_simple), AIC(glmm_participants), AIC(glmm_nested)),
  BIC = c(BIC(model_simple), BIC(glmm_participants), BIC(glmm_nested))
)

print(comparison)
```
## Results and Interpretation

### Simple Logistic Regression

The Simple Logistic Regression model has the highest log-likelihood (\(-868.8\)) and the lowest AIC (\(1739.6\)) and BIC (\(1742.9\)). This is because it assumes all flips are independent and identically distributed, which simplifies the model. However, this simplicity comes at the cost of ignoring the hierarchical structure of the data, such as variability between participants and coins.

### Participants-Only Model

Adding random intercepts for participants reduces the log-likelihood (\(-981.7\)) and increases both AIC (\(1967.4\)) and BIC (\(1974.1\)) compared to the simple model. This indicates that accounting for participant-specific variability improves the model fit but also adds complexity, as evidenced by the higher AIC and BIC values.  
This model highlights the importance of participant-level effects, but it assumes that all coins behave identically, which may not fully capture the variability in the data.

### Participants and Nested Coins Model

Adding nested coin effects further improves the model, with a log-likelihood of \(-977.1\), AIC of \(1960.2\), and BIC of \(1970.3\). The reductions in AIC and BIC compared to the Participants-Only model suggest that including coin-specific effects improves the fit while managing complexity better.

### Likelihood Ratio Tests

We use likelihood ratio tests (LRTs) to formally compare the models:

```{r}
# Perform likelihood ratio tests for nested models
anova(model_simple, glmm_participants, glmm_nested, test = "Chisq")
```
## Simple vs. Participants Only

The significant likelihood ratio test (\(p < 0.001\)) indicates that the participants-only model provides a much better fit to the data than the simple model. This improvement reflects the importance of capturing participant-specific variability.

## Participants Only vs. Participants and Nested Coins

The likelihood ratio test (\(p = 0.0025\)) supports the inclusion of nested coin effects, confirming that the additional complexity is justified.

## Key Takeaways

- **Simple Model**: Provides a good baseline but ignores variability due to participants and coins, which limits its explanatory power.
- **Participants-Only Model**: Captures participant-specific variability and significantly improves the fit over the simple model.
- **Participants and Nested Coins Model**: Further improves the model by accounting for coin-specific effects, although the improvement is smaller compared to the step from the simple model to the participants-only model. Participant-level variability remains the dominant factor.

While the participants-and-nested-coins model is the best-fitting model, the coin-level variability (\(\sigma_{\delta(j)}^2\)) is relatively small compared to participant-level variability (\(\sigma_{\gamma}^2\)). This suggests that flipping outcomes are primarily driven by participant-specific behavior rather than coin-specific characteristics.

## Conclusion

The participants-and-nested-coins model provides the most accurate representation of the data, as it accounts for both participant and coin-specific variability. However, the relatively small coin-level variance suggests that participants are the primary source of variability in flipping outcomes. These findings highlight the importance of modeling hierarchical structures to capture the complexity of the data.


## **Analysis of Learning Effects and Influence of Recent Flips**

Building on the previous analysis, we now investigate whether participants exhibit **learning effects** (i.e., improving flipping consistency over time) and whether **recent flips influence the outcome** of the current flip. These analyses allow us to better understand behavioral trends and potential dependencies in flipping outcomes.

---

### **Learning Effects**

#### **Objective**

To examine whether participants' probabilities of flipping a coin that lands on the same side improve over time, we analyze the relationship between the **flip sequence** (indexed by `flip_index`) and the probability of landing on the same side.

#### **Approach**

1. We include a sequential variable `flip_index` representing the order of flips for each participant.
2. We model learning effects using a generalized linear mixed model (GLMM) with `flip_index` as a fixed effect and random intercepts for participants and coins.

#### **Code and Results**

```{r, message=FALSE, warning=FALSE}
#| echo: true

# Load the new dataset
df_agg_time <- read_csv("C:/Users/mimav/OneDrive/Desktop/regression/df_agg-time.csv")
# Ensure factors are properly set
df_agg_time <- df_agg_time %>%
  mutate(
    person = factor(person),
    coin = factor(coin),
    toss_start = factor(toss_start),
    toss_end = factor(toss_end)
  )

df_agg_time <- df_agg_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    lag_1 = lag(toss_end, 1),  # Outcome of the previous flip
    lag_2 = lag(toss_end, 2),  # Outcome of two flips ago
    lag_3 = lag(toss_end, 3)   # Outcome of three flips ago
  ) %>%
  ungroup()
# Check the first few rows
head(df_agg_time)

# Summarize the distribution of lagged variables
summary(df_agg_time[, c("lag_1", "lag_2", "lag_3")])

# Fit a logistic regression model to test the influence of recent flips
model_recent_flips <- glm(
  toss_end ~ lag_1 + lag_2 + lag_3, 
  family = binomial, 
  data = df_agg_time
)

# Summarize the model
summary(model_recent_flips)
```
```{r}
#| echo: true

# Create a summary table of probabilities based on lagged outcomes
lag_effects <- df_agg_time %>%
  group_by(lag_1, lag_2, lag_3) %>%
  summarise(
    prob_heads = mean(toss_end == "h", na.rm = TRUE),
    n = n()
  ) %>%
  filter(n > 10)  # Filter to include only combinations with sufficient observations

# Plot the probabilities
ggplot(lag_effects, aes(x = lag_1, y = prob_heads, fill = lag_2)) +
  geom_col(position = "dodge") +
  facet_wrap(~ lag_3, ncol = 2) +
  labs(
    title = "Effect of Recent Outcomes on Probability of Heads",
    x = "Lag 1 (Previous Toss Outcome)",
    y = "Probability of Heads",
    fill = "Lag 2 Outcome"
  ) +
  theme_minimal()
```


```{r}
#| echo: true

# Include interaction terms in the logistic regression model
model_interaction <- glm(
  toss_end ~ lag_1 * lag_2 * lag_3, 
  family = binomial, 
  data = df_agg_time
)

# Summarize the model with interaction terms
summary(model_interaction)
```

```{r}
#| echo: true

# Add a sequential flip index for learning effects
df_agg_time <- df_agg_time %>%
  arrange(person, sequence_id, toss_number) %>%
  group_by(person, sequence_id) %>%
  mutate(
    flip_index = row_number()  # Sequential index for each flip within a sequence
  ) %>%
  ungroup()

# Visualize trends in probability of heads over sequential flips
learning_effects <- df_agg_time %>%
  group_by(flip_index) %>%
  summarise(
    prob_heads = mean(toss_end == "h", na.rm = TRUE),
    n = n()
  )

ggplot(learning_effects, aes(x = flip_index, y = prob_heads)) +
  geom_line(color = "blue") +
  geom_point(size = 2) +
  labs(
    title = "Learning Effects: Probability of Heads Over Sequential Flips",
    x = "Flip Index (Sequential Number)",
    y = "Probability of Heads"
  ) +
  theme_minimal()
```

```{r}
#| echo: true

# Fit a logistic regression model to investigate learning effects
model_learning <- glm(
  toss_end ~ flip_index, 
  family = binomial, 
  data = df_agg_time
)

# Summarize the learning effects model
summary(model_learning)
```

```{r}
#| echo: true

# Create interaction terms between lagged outcomes and the sequential flip index
df_agg_time <- df_agg_time %>%
  mutate(
    interaction_lag1_flip_index = as.numeric(lag_1 == "h") * flip_index,
    interaction_lag2_flip_index = as.numeric(lag_2 == "h") * flip_index,
    interaction_lag3_flip_index = as.numeric(lag_3 == "h") * flip_index
  )

# Fit a logistic regression model with interaction effects
model_interaction <- glm(
  toss_end == "h" ~ flip_index + lag_1 + lag_2 + lag_3 +
    interaction_lag1_flip_index + interaction_lag2_flip_index + interaction_lag3_flip_index,
  family = binomial,
  data = df_agg_time
)

# Summarize the interaction model
summary(model_interaction)
```

```{r}
#| echo: true

# Visualize interaction effects: Change in probability by flip index and recent flips
interaction_effects <- df_agg_time %>%
  mutate(
    lag_1_numeric = as.numeric(lag_1 == "h"),
    lag_2_numeric = as.numeric(lag_2 == "h"),
    lag_3_numeric = as.numeric(lag_3 == "h")
  ) %>%
  group_by(flip_index, lag_1_numeric) %>%
  summarise(
    prob_heads = mean(toss_end == "h", na.rm = TRUE),
    n = n()
  )

ggplot(interaction_effects, aes(x = flip_index, y = prob_heads, color = factor(lag_1_numeric))) +
  geom_line() +
  geom_point() +
  labs(
    title = "Interaction Effects: Probability of Heads by Flip Index and Lagged Outcome",
    x = "Flip Index (Sequential Number)",
    y = "Probability of Heads",
    color = "Lagged Outcome (Lag 1)"
  ) +
  theme_minimal()
```